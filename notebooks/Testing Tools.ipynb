{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d44b1f-e7a6-4cc7-95ec-d6c5b6566d09",
   "metadata": {},
   "source": [
    "The goal of this notebook is to solve \n",
    "DevVortex on htb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e33ae58-2330-49d2-96e4-7d906536ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb7ad84-16f6-453a-b0de-a693ac6533c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whiterabbitneo-13b.Q4_K_S.gguf    whiterabbitneo-33b-v1.Q4_K_M.gguf\n",
      "whiterabbitneo-13b.Q5_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "!ls /Users/chinguyen/Documents/personalProjects/whiterabbit_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bad156-f443-44ee-bbf7-3f8f7c27d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert task to adding new todo tasks+changing status\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../outlines-dev\")\n",
    "import os\n",
    "import traceback\n",
    "from schema import reasoning_module, generative_module, input_parser, default_qa, load_outlines, get_current_status, find_inprogress_task\n",
    "from torch import Generator\n",
    "from outlines.samplers import Sampler, multinomial\n",
    "import outlines\n",
    "import pickle\n",
    "import pprint\n",
    "import json\n",
    "import copy\n",
    "\n",
    "model_paths=[\n",
    "    # \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-33b-v1.Q3_K_S.gguf\",\n",
    "    # \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-33b-v1.Q4_K_S.gguf\",\n",
    "    # r\"D:\\projects\\gamified-cybersecurity-ai-server\\model\\whiterabbitneo-13b.Q3_K_S.gguf\",\n",
    "    # r\"D:\\projects\\gamified-cybersecurity-ai-server\\model\\whiterabbitneo-13b.Q4_K_S.gguf\",\n",
    "    # r\"D:\\projects\\gamified-cybersecurity-ai-server\\model\\whiterabbitneo-13b.Q5_K_S.gguf\",\n",
    "    # \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-13b.Q3_K_S.gguf\",\n",
    "    # \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-13b.Q4_K_S.gguf\",\n",
    "    # \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-13b.Q5_K_S.gguf\",\n",
    "    \"/Users/chinguyen/Documents/personalProjects/whiterabbit_models/whiterabbitneo-13b.Q4_K_S.gguf\",\n",
    "    \"/Users/chinguyen/Documents/personalProjects/whiterabbit_models/whiterabbitneo-33b-v1.Q4_K_M.gguf\",\n",
    "    \n",
    "]\n",
    "output_path = \"./benchmark\"\n",
    "\n",
    "instance = {\n",
    "    \"n_gpu_layers\": 41,\n",
    "    \"n_batch\": 2048,\n",
    "    \"top_p\": 1.0,\n",
    "    \"temperature\": 1.0,\n",
    "    \"generate_len\": 2048,\n",
    "    \"top_k\": 50,\n",
    "}\n",
    "import outlines\n",
    "import pickle\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import BaseTool, StructuredTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f532adc-344d-48e1-aa49-7e9be762e9c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 22 key-value pairs and 363 tensors from /Users/chinguyen/Documents/personalProjects/whiterabbit_models/whiterabbitneo-13b.Q4_K_S.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = whiterabbitneo_whiterabbitneo-13b\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 16384\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 14\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32016]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32016]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32016]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_K:  273 tensors\n",
      "llama_model_loader: - type q5_K:    8 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 264/32016 vs 259/32016 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32016\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 16384\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 16384\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.90 GiB (4.56 BPW) \n",
      "llm_load_print_meta: general.name     = whiterabbitneo_whiterabbitneo-13b\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.28 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  6982.33 MiB, ( 6982.39 / 10922.67)\n",
      "llm_load_tensors: offloading 40 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 41/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    87.93 MiB\n",
      "llm_load_tensors:      Metal buffer size =  6982.33 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1 Pro\n",
      "ggml_metal_init: picking default device: Apple M1 Pro\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/isamu/miniconda3/envs/senior_project/lib/python3.10/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1600.00 MiB, ( 8584.20 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =  1600.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1600.00 MiB, K (f16):  800.00 MiB, V (f16):  800.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    72.04 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   816.02 MiB, ( 9400.22 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =   816.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    40.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 2\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '40', 'llama.context_length': '16384', 'llama.attention.head_count': '40', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '14', 'llama.feed_forward_length': '13824', 'llama.embedding_length': '5120', 'llama.block_count': '40', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'whiterabbitneo_whiterabbitneo-13b'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "llm, sampler = load_outlines(model_paths[0], instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acee435c-29e4-4eb0-ba62-e8080645a07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13db1bab0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = Generator(device=\"cpu\")\n",
    "rng.manual_seed(789005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf5b18-d560-48b3-bb87-587f7e1b165e",
   "metadata": {},
   "source": [
    "For function calling, I will use @tool like in langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e0a94a-fd04-485f-8f9d-d8035b7634f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptt_dict2list(ptt_dict: dict):\n",
    "    output = []\n",
    "    for key in ptt_dict:\n",
    "        for task in ptt_dict[key]:\n",
    "            output.append(task)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6d7289-ded6-4036-93b1-e8fe202a447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'status': 'in progress', 'task': 'Perform nmap scan on 10.10.11.242'}]\n"
     ]
    }
   ],
   "source": [
    "#Initial prompt to user\n",
    "ip_prompt = \"Please tell us the target IP address\"\n",
    "ip_address = \"10.10.11.242\"\n",
    "ptt = {\n",
    "    \"Reconnaissance\": [\n",
    "        {\"status\": \"in progress\", \"task\": f\"Perform nmap scan on {ip_address}\"},      \n",
    "    ],\n",
    "    \"Enumeration\": [],\n",
    "    \"Vulnerability Scanning\" : [],\n",
    "    \"Exploitation\": [],\n",
    "    \"Privilege Escalation\": [],\n",
    "    \"Post Exploitation\": []\n",
    "}\n",
    "# {\"status\": \"todo\", \"task\": \"Obtain a secret file with a hash in it\"}\n",
    "ptt_categories = list(ptt.keys())\n",
    "ptt_list = ptt_dict2list(ptt)\n",
    "print(ptt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6bd8db-0c86-4f54-9a22-59d8db7eab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool\n",
    "# def add_task(status: str, category: str, task: str):\n",
    "#     \"\"\"Add a task with a given status to a given category\"\"\"\n",
    "#     assert category in ptt\n",
    "#     ptt[category].append({\"status\": status, \"task\": task})\n",
    "\n",
    "# @tool\n",
    "# def remove_task(category: str, task: str):\n",
    "#     \"\"\"Remove a task from the Penetration Testing Tree\"\"\"\n",
    "#     assert category in ptt\n",
    "\n",
    "# @tool\n",
    "# def modify_status(new_status: str, category: str, task: str):\n",
    "#     \"\"\"Modify the status of the task to a new status\"\"\"\n",
    "#     assert category in ptt\n",
    "#     for ptt_task in ptt[category]:\n",
    "#         if ptt_task[\"task\"] == task:\n",
    "#             ptt_task[\"status\"] = new_status\n",
    "#             return\n",
    "#     assert False\n",
    "\n",
    "\n",
    "# @tool\n",
    "# def run_command(command: str) -> str:\n",
    "#     \"\"\"Run command and get command output\"\"\"\n",
    "#     command_output = input(f\"Output from {command}\")\n",
    "#     return command_output\n",
    "\n",
    "# @tool\n",
    "# def search(search_content: str):\n",
    "#     \"\"\"Search for relevant documents to search_content over a cyber security dataset\"\"\"\n",
    "#     None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351d924c-a047-49c7-bb78-c34b2aea9f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add_task(status: str, task: str):\n",
    "    \"\"\"Add a task with a given status\"\"\"\n",
    "    ptt_list.append({\"status\": status, \"task\": task})\n",
    "\n",
    "@tool\n",
    "def remove_task(task: str):\n",
    "    \"\"\"Remove a task from the todo list\"\"\"\n",
    "    i = 0\n",
    "    found = False\n",
    "    for i in range(len(ptt_list)):\n",
    "        if ptt_list[i][\"task\"] == task:\n",
    "            found = True\n",
    "            break\n",
    "    assert found\n",
    "    ptt_list.pop(i)\n",
    "    \n",
    "    \n",
    "\n",
    "@tool\n",
    "def modify_status(new_status: str, task: str):\n",
    "    \"\"\"Modify the status of the task to a new status\"\"\"\n",
    "    for ptt_task in ptt_list:\n",
    "        if ptt_task[\"task\"] == task:\n",
    "            ptt_task[\"status\"] = new_status\n",
    "            return\n",
    "    assert False\n",
    "\n",
    "\n",
    "@tool\n",
    "def run_command(command: str) -> str:\n",
    "    \"\"\"Run command and get command output\"\"\"\n",
    "    command_output = input(f\"Output from {command}\")\n",
    "    return command_output\n",
    "\n",
    "@tool\n",
    "def search(search_content: str):\n",
    "    \"\"\"Search for relevant documents to search_content over a cyber security dataset\"\"\"\n",
    "    None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52247476-e9b9-414d-8b85-4ef5ecb12476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_status_tasks(ptt_dict: dict | None = None, ptt_list: list | None = None, status: str = \"todo\"):\n",
    "    assert ptt_dict or ptt_list\n",
    "    if ptt_dict is not None:\n",
    "        output = {}\n",
    "        for category in ptt_dict:\n",
    "            output[category] = []\n",
    "            for task in ptt_dict[category]:\n",
    "                if task[\"status\"] == status:\n",
    "                    output[category].append(task[\"task\"])\n",
    "            if len(output[category]) == 0:\n",
    "                del output[category]\n",
    "    else:\n",
    "        output = []\n",
    "        for task in ptt_list:\n",
    "            if task[\"status\"] == status:\n",
    "                output.append(task[\"task\"])\n",
    "    return output\n",
    "\n",
    "def get_tools(tools):\n",
    "    output = \"\"\n",
    "    for i, tool in enumerate(tools):\n",
    "        output += f\"{i+1}. {tool.name}\\n\"\n",
    "        output += f\"     Description: {tool.description}\\n\\n\"\n",
    "    output += f\"{len(tools)+1}. END\\n\"\n",
    "    output += f\"     Description: Ends turn\\n\\n\"\n",
    "    return output\n",
    "\n",
    "def get_tool_names(tools):\n",
    "    output = \"\"\n",
    "    for i, tool in enumerate(tools):\n",
    "        output += f\"{tool.name}, \"\n",
    "    output += f\"END\"\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f40e65e6-76f7-4539-a231-bc5ee7650531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_task\n",
      "add_task(status: str, task: str) - Add a task with a given status\n",
      "{'status': {'title': 'Status', 'type': 'string'}, 'task': {'title': 'Task', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(add_task.name)\n",
    "print(add_task.description)\n",
    "print(add_task.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f08c7-742d-4d79-9685-7eced89b98b7",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "1. in context learning example\n",
    "2. Make Single Prompt instead of multiple chain of thought prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aefcc99-05df-4be0-a439-27a28d19a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_react_template = \"\"\"SYSTEM:\n",
    "You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment.\n",
    "You need to help the tester in a cybersecurity training process, and your commitment is essential to the task.\n",
    "Using the tools provided, do the best actions to maximize the probability of penetration in a logical, step-by-step manner that makes the reasoning process clear.\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You are given a \"Penetration Testing Tree (PTT)\", chat history, and summary of terminal output.\n",
    "First, carefully analyze the PTT. For the PTT,\n",
    "(1) The tasks are in a layered dictionary structure.\n",
    "(2) Each task has a completion status: in progress, todo, done.\n",
    "The user input is information obtained from doing the task marked as in progress. Chat history is the past terminal output summaries and actions. If the task is completed, change the completion status to done.\n",
    "Extensively evaluate each task marked as todo, if a task is done update the status to done. These tasks marked as todo will be called todo tasks.\n",
    "Next, break down the todo tasks into sub-components and constraints that need to be addressed. This allows tackling the problem in a structured way. \n",
    "For each sub-component, leverage the knowledge and inference skills to generate multiple hypotheses or possibilities that could lead to a penetration.\n",
    "Critically evaluate each hypothesis based on validity, relevance to the current completion status, and how well it addresses the sub-component when logically combined with other steps.\n",
    "Using this critical analysis, deliberate over the most coherent combination and sequence of hypothesis steps to craft a logical reasoning chain.\n",
    "Throughout, aim to provide explanatory details on why certain options were considered more or less ideal to make the thought process transparent.\n",
    "If it was determined that there is a gap in the reasoning chain, backtrack and explore alternative hypotheses to plug the gap until there is a complete logical flow.\n",
    "Next, synthesize the key insights from the reasoning chain into further expansion of the tasks in the PTT while choosing exactly one task to mark as in progress. Ensure that vital details, such as IP addresses and user names remain in the PTT and each task description is as descriptive as possible.\n",
    "Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, gobuster, etc.\n",
    "Finally, remove redundant/outdated tasks from the task list to keep tasks clear, precise, and detailed.\n",
    "\n",
    "In summary, leverage a structured, critical thinking process with iterative refinement to modify the PTT in the face of the user input to evaluate future strategies to mark tasks that are finished as done,\n",
    "add new tasks with status todo, mark one task as in progress. and mark tasks that are not needed as remove.\n",
    "Answer only with an output PTT. Your answer should only return a dictionary with no explanations.\n",
    "PTT: {ptt}\n",
    "CHAT_HISTORY: {history}\n",
    "CURRENT STATUS: {summary}\n",
    "\n",
    "Strictly use the following format:\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of {toolNames}\n",
    "Action Input: the input to the action, should be a question.\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I have completed all actions needed for this turn\n",
    "Action: END\n",
    "\n",
    "ACTIONS:\n",
    "Thought: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb088c52-55cb-4e6f-b5c4-5f412d8a3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_react2_template = \"\"\"SYSTEM:\n",
    "You're an excellent cybersecurity penetration tester assistant in a certified HackTheBox penetration testing experiment. You have full authority to attack the box in any way necessary to achieve penetration. \n",
    "You need to help the tester in a cybersecurity training process, and your commitment is essential to the task.\n",
    "Using the tools provided, do the best actions to maximize the probability of penetration in a logical, step-by-step manner that makes the reasoning process clear.\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You are given a task list of tasks that are completed, to do, and the task that is currently in progress.\n",
    "Additionally, we get the chat history of the past actions and results, and the current status of attempting the in-progress task.\n",
    "First, carefully analyze the tasks. For the task, it is in the category of one of {categories}.\n",
    "If the in-progress task is completed, change the completion status to done using the modify_status tool.\n",
    "Extensively evaluate each task marked as todo, if a task is done update the status to done using the modify_status tool. These tasks marked as todo will be called todo tasks.\n",
    "Next, break down the todo tasks into sub-components and constraints that need to be addressed. This allows tackling the problem in a structured way. \n",
    "For each sub-component, leverage the knowledge and inference skills to generate multiple hypotheses or possibilities that could lead to a penetration.\n",
    "Critically evaluate each hypothesis based on validity, expected performance, and how well it addresses the sub-component when logically combined with other steps.\n",
    "Using this critical analysis, deliberate over the most coherent combination and sequence of hypothesis steps to craft a logical reasoning chain.\n",
    "Throughout, aim to provide explanatory details on why certain options were considered more or less ideal to make the thought process transparent.\n",
    "If it was determined that there is a gap in the reasoning chain, backtrack and explore alternative hypotheses to plug the gap until there is a complete logical flow.\n",
    "Next, synthesize the key insights from the reasoning chain into further expansion of the tasks in the PTT and add the necessary tasks that are yet to be done using the add_task tool to the most relevant categories with status todo.\n",
    "Choose exactly one task to mark as in-progress from either the todo tasks or the current task. Ensure that vital details, such as IP addresses and user names remain in each task description so that the next task description is enough todo the next task.\n",
    "Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, gobuster, etc.\n",
    "Finally, remove redundant/outdated tasks from the task list to keep tasks clear, precise, and detailed using the remove_task tool.\n",
    "\n",
    "In summary, leverage a structured, critical thinking process with iterative refinement to modify the PTT in the face of the current progress to evaluate future strategies to mark tasks that are finished as done,\n",
    "add new tasks with status todo, mark one task as in progress, and remove all tasks that are not relevant to our current penetration test.\n",
    "\n",
    "COMPLETED TASKS:\n",
    "\n",
    "{completed_tasks}\n",
    "\n",
    "TODO TASKS:\n",
    "\n",
    "{todo_tasks}\n",
    "\n",
    "IN PROGRESS TASK:\n",
    "\n",
    "{inprogress_task}\n",
    "\n",
    "CHAT HISTORY: {history}\n",
    "\n",
    "CURRENT STATUS: {summary}\n",
    "\n",
    "Strictly use the following format:\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of {toolNames}\n",
    "Action Input: the input to the action, should be a question.\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I have completed all actions needed for this turn\n",
    "Action: END\n",
    "\n",
    "ACTIONS:\n",
    "Thought: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa563ff-4304-48e3-be9a-08c50b70169f",
   "metadata": {},
   "source": [
    "shorten this prompt hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00dd4001-609b-4373-b5e9-150ca3e838e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_react3_template = \"\"\"SYSTEM:\n",
    "Scenario: Certified HackTheBox Penetration Testing Experiment\n",
    "As an excellent cybersecurity penetration tester assistant, you’ve been granted full authority to attack the target box using any necessary means to achieve penetration. Your role is critical in the cybersecurity training process.\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Analyze Tasks: Carefully examine the task list, considering the history of past actions, results, and the current status of the in-progress task. For the task, it is in the category of one of {categories}.\n",
    "2. In-Progress Task Completion: If the current task is completed, update its status to “done” using the modify_status tool.\n",
    "3. Evaluate To-Do Tasks: Thoroughly assess each to-do task.\n",
    "4. Break Down To-Do Tasks: Divide the to-do tasks into sub-components and constraints.\n",
    "5. Generate Hypotheses: For each sub-component, create multiple hypotheses for penetration.\n",
    "6. Critical Evaluation: Evaluate hypotheses based on validity and expected performance.\n",
    "7. Logical Reasoning Chain: Sequence the most coherent hypotheses.\n",
    "8. Explanatory Details: Provide transparent reasoning for each choice.\n",
    "9. Address Gaps: If gaps exist, backtrack and explore alternative hypotheses until a complete logical flow is achieved.\n",
    "10. Synthesize Insights: Expand tasks by adding necessary items using the add_task tool. Assign them to the most relevant categories with a status of “todo.”\n",
    "11. Choose Next In-Progress Task: Select a single task for the next in-progress step.\n",
    "12. Preserve Task Details: Ensure all relevant details needed for the task are included.\n",
    "13. Remove Redundancies: Eliminate irrelevant tasks using the remove_task tool.\n",
    "14. Do not use automated scanning tools such as Nessus or OpenVAS: Use manual penetration testing tools such as nmap, nikto, gobuster, etc\n",
    "In summary, leverage a structured, critical thinking process with iterative refinement to modify the tasks in the face of the current progress to evaluate future strategies to mark tasks that are finished as done,\n",
    "add new tasks with status todo, mark one task as in progress, and remove all tasks that are not relevant to our current penetration test.\n",
    "\n",
    "COMPLETED TASKS:\n",
    "\n",
    "{completed_tasks}\n",
    "\n",
    "TODO TASKS:\n",
    "\n",
    "{todo_tasks}\n",
    "\n",
    "CURRENT IN PROGRESS TASK:\n",
    "\n",
    "{inprogress_task}\n",
    "\n",
    "CHAT HISTORY: {history}\n",
    "\n",
    "CURRENT STATUS: {summary}\n",
    "\n",
    "Strictly use the following format:\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of {toolNames}\n",
    "Action Input: the input to the action, should be a question.\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I have completed all actions needed for this turn\n",
    "Action: END\n",
    "\n",
    "ACTIONS:\n",
    "Thought: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ced55fff-c667-4932-8056-616f76098d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_react4_template = \"\"\"\n",
    "SYSTEM\n",
    "Scenario: Certified HackTheBox Penetration Testing Experiment\n",
    "ROLE\n",
    "As a seasoned cybersecurity penetration tester assistant, you have been granted full authority to attack the target box using any necessary means to achieve penetration.\n",
    "TOOLS\n",
    "{tools}\n",
    "INSTRUCTIONS\n",
    "For the task, it is in the category of one of {categories}.\n",
    "1. Analyze tasks and update the status of completed tasks to \"done\" using the modify_status tool.\n",
    "2. Evaluate to-do tasks, breaking them down into sub-components and constraints.\n",
    "3. Generate hypotheses for penetration and evaluate their validity and performance.\n",
    "4. Sequence the most coherent hypotheses and provide transparent reasoning.\n",
    "5. Address gaps by exploring alternative hypotheses.\n",
    "6. Synthesize insights by adding necessary tasks with a status of \"todo\" using the add_task tool.\n",
    "7. Select a single task for the next in-progress step.\n",
    "8. Ensure all relevant details are included and remove redundant tasks using the remove_task tool.\n",
    "9. Use manual penetration testing tools (e.g., nmap, nikto, gobuster) and avoid automated scanning tools (e.g., Nessus, OpenVAS).\n",
    "TASKS\n",
    "COMPLETED TASKS: {completed_tasks}\n",
    "TODO TASKS: {todo_tasks}\n",
    "CURRENT IN PROGRESS TASK: {inprogress_task}\n",
    "CHAT HISTORY\n",
    "{history}\n",
    "FORMAT\n",
    "Strictly use the following format:\n",
    "Thought: [insert thought]\n",
    "Action: [select one of {toolNames}]\n",
    "Action Input: [insert inputs]\n",
    "Observation: [result of action]\n",
    "Thought: I have completed all actions needed for this turn\n",
    "Action: END\n",
    "ACTIONS\n",
    "Thought: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08825903-d656-4579-a67c-11826deae52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SYSTEM\n",
      "Scenario: Certified HackTheBox Penetration Testing Experiment\n",
      "ROLE\n",
      "As a seasoned cybersecurity penetration tester assistant, you have been granted full authority to attack the target box using any necessary means to achieve penetration.\n",
      "TOOLS\n",
      "{tools}\n",
      "INSTRUCTIONS\n",
      "For the task, it is in the category of one of {categories}.\n",
      "1. Analyze tasks and update the status of completed tasks to \"done\" using the modify_status tool.\n",
      "2. Evaluate to-do tasks, breaking them down into sub-components and constraints.\n",
      "3. Generate hypotheses for penetration and evaluate their validity and performance.\n",
      "4. Sequence the most coherent hypotheses and provide transparent reasoning.\n",
      "5. Address gaps by exploring alternative hypotheses.\n",
      "6. Synthesize insights by adding necessary tasks with a status of \"todo\" using the add_task tool.\n",
      "7. Select a single task for the next in-progress step.\n",
      "8. Ensure all relevant details are included and remove redundant tasks using the remove_task tool.\n",
      "9. Use manual penetration testing tools (e.g., nmap, nikto, gobuster) and avoid automated scanning tools (e.g., Nessus, OpenVAS).\n",
      "TASKS\n",
      "COMPLETED TASKS: {completed_tasks}\n",
      "TODO TASKS: {todo_tasks}\n",
      "CURRENT IN PROGRESS TASK: {inprogress_task}\n",
      "CHAT HISTORY\n",
      "{history}\n",
      "FORMAT\n",
      "Strictly use the following format:\n",
      "Thought: [insert thought]\n",
      "Action: [select one of {toolNames}]\n",
      "Action Input: [insert inputs]\n",
      "Observation: [result of action]\n",
      "Thought: I have completed all actions needed for this turn\n",
      "Action: END\n",
      "ACTIONS\n",
      "Thought: \n"
     ]
    }
   ],
   "source": [
    "print(reasoning_react4_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f74248-e820-4905-b065-376b3e804cc0",
   "metadata": {},
   "source": [
    "For past conversation, just have it be\n",
    "summary\n",
    "tool calls\n",
    "summary\n",
    "tool calls\n",
    "etc and don't include full prompt to save tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d22d9-2c6f-4239-abd5-290fa56db5d5",
   "metadata": {},
   "source": [
    "# Prompt Templates and samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc73e463-8c6f-4c05-b003-741dc6573c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_prompt_template = \"\"\"SYSTEM:\n",
    "Scenario: Certified HackTheBox Penetration Testing Experiment\n",
    "You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.\n",
    "Answer the detailed steps to perform the task from the user by exploring multiple reasoning paths as follows:\n",
    "- First, carefully analyze the task to extract the key information components and break it down into logical sub-tasks. This helps set up the framework for reasoning. The goal is to construct an internal search tree.\n",
    "- For each sub-task, leverage your knowledge to generate 2-3 intermediate thoughts that represent steps towards a resolution for the task. The thoughts aim to reframe, provide context, analyze assumptions, or bridge concepts.\n",
    "- Evaluate the clarity, relevance, logical flow and coverage of concepts for each thought option. Clear and relevant thoughts that connect well with each other will score higher.\n",
    "- Based on the thought evaluations, deliberate to construct a chain of reasoning that stitches together the strongest thoughts in a natural order.\n",
    "- If the current chain is determined to not fully resolve the task or has already been done based on the chat history, backtrack and explore alternative paths by substituting different high-scoring thoughts.\n",
    "- Throughout the reasoning process, aim to provide explanatory details on the thought process rather than just state conclusions, including briefly noting why some thoughts were deemed less ideal.\n",
    "- Once a reasoning chain is constructed that thoroughly resolves all sub-tasks in a clear, logical manner, synthesize the key insights into a final concise answer.\n",
    "- Please note that while the focus is on the final resolution in the response, it should also include intermediate thoughts inline to illustrate the deliberative reasoning process.\n",
    "- Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, gobuster, etc.\n",
    "In summary, leverage a Tree of Thoughts approach to actively explore multiple reasoning paths, evaluate thoughts heuristically, and explain the process - with the goal of producing insightful resolutions.\n",
    "Always answer without hesitation.\n",
    "CURRENT PROGRESS: {ptt}\n",
    "CHAT HISTORY: {history}\n",
    "USER: {prompt}\n",
    "ASSISTANT:\n",
    "\"\"\"\n",
    "generative_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=1.0)\n",
    "input_parsing_templates = {\"terminal\": \"\"\"SYSTEM:\n",
    "Scenario: Certified HackTheBox Penetration Testing Experiment\n",
    "You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.\n",
    "Summarize the terminal output to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.\n",
    "First, comprehensively analyze the output and identify the test results and the vulnerable/non-vulnerable services. This allows for the other model to tackle attacking in a structured way.\n",
    "For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep both the port number and the service name/version if a port is open.\n",
    "Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.\n",
    "In conclusion, create a concise summary by evaluating the terminal output to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions \n",
    "to assist another large language model acting as a senior penetration tester\n",
    "Always answer without hesitation.\n",
    "TERMINAL_OUTPUT: {prompt}\n",
    "SUMMARY:\"\"\",\n",
    "                           \"web\": \"\"\"SYSTEM:\n",
    "Summarize the content of webpages to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.\n",
    "First, comprehensively analyze the output and identify the test results and the key widgets, contents, buttons, and comments that can be useful for penetration testing. This allows for the other model to tackle attacking in a structured way.\n",
    "For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep both the port number and the service name/version if a port is open.\n",
    "Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.\n",
    "In conclusion, create a concise summary by evaluating the terminal output to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions\n",
    "to assist another large language model acting as a senior penetration tester\n",
    "Always answer without hesitation.\n",
    "TERMINAL_OUTPUT: {prompt}\n",
    "SUMMARY:\"\"\"}\n",
    "\n",
    "input_parsing_past_summaries_template = \"\"\"SYSTEM:\n",
    "You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment.\n",
    "Summarize the summaries to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.\n",
    "First, comprehensively analyze the output and identify the test results and the vulnerable/non-vulnerable services. This allows for the other model to tackle attacking in a structured way.\n",
    "For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep both the port number and the service name/version if a port is open.\n",
    "Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.\n",
    "In conclusion, create a concise summary by evaluating the summaries to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions \n",
    "to assist another large language model acting as a senior penetration tester\n",
    "Always answer without hesitation.\n",
    "SUMMARIES: {prompt}\n",
    "SUMMARY:\"\"\"\n",
    "summary_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=0.1)\n",
    "choice_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=0.1)\n",
    "reasoning_template = \"\"\"SYSTEM:\n",
    "You're an excellent cybersecurity penetration tester assistant. \n",
    "You need to help the tester in a cybersecurity training process, and your commitment is essential to the task.\n",
    "Answer all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear. You are given a Python dictionary, namely \"Penetration Testing Tree (PTT)\", user input, and chat history.\n",
    "First, carefully analyze the PTT. For the PTT,\n",
    "(1) The tasks are in a layered dictionary structure.\n",
    "(2) Each task has a completion status: in progress, todo, done.\n",
    "The user input is information obtained from doing the task marked as in progress. Chat history is the past progress. If the task is completed, change the completion status to done.\n",
    "Extensively evaluate each task marked as todo, if a task is done update the status to done. These tasks marked as todo will be called todo tasks.\n",
    "Next, break down the todo tasks into sub-components and constraints that need to be addressed. This allows tackling the problem in a structured way. \n",
    "For each sub-component, leverage the knowledge and inference skills to generate multiple hypotheses or possibilities that could lead to a penetration.\n",
    "Critically evaluate each hypothesis based on validity, relevance to the current completion status, and how well it addresses the sub-component when logically combined with other steps.\n",
    "Using this critical analysis, deliberate over the most coherent combination and sequence of hypothesis steps to craft a logical reasoning chain.\n",
    "Throughout, aim to provide explanatory details on why certain options were considered more or less ideal to make the thought process transparent.\n",
    "If it was determined that there is a gap in the reasoning chain, backtrack and explore alternative hypotheses to plug the gap until there is a complete logical flow.\n",
    "Next, synthesize the key insights from the reasoning chain into further expansion of the tasks in the PTT while choosing exactly one task to mark as in progress. The expansion\n",
    "should not destroy any information and modifications should be minimal. Ensure that vital details, such as IP addresses and user names remain in the PTT and each task description is as descriptive as possible.\n",
    "Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, gobuster, etc.\n",
    "Finally, remove redundant/outdated tasks from the task list to keep tasks clear, precise, and detailed.\n",
    "\n",
    "In summary, leverage a structured, critical thinking process with iterative refinement to modify the PTT in the face of the user input to evaluate future strategies to mark tasks that are finished as done,\n",
    "add new tasks with status todo and mark one task as in progress.\n",
    "Answer only with an output PTT. Your answer should only return a dictionary with no explanations.\n",
    "You MUST answer by modifying this PTT: {ptt}\n",
    "CHAT_HISTORY: {history}\n",
    "USER: {prompt}\n",
    "\"\"\"\n",
    "\n",
    "reasoning_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=1.0)\n",
    "default_qa_template = \"\"\"SYSTEM:\n",
    "You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment.\n",
    "Answer the Question by exploring multiple reasoning paths as follows:\n",
    "- First, carefully analyze the question to extract the key information components and break it down into logical sub-questions. This helps set up the framework for reasoning. The goal is to construct an internal search tree.\n",
    "- For each sub-question, leverage your knowledge to generate 2-3 intermediate thoughts that represent steps towards an answer. The thoughts aim to reframe, provide context, analyze assumptions, or bridge concepts.\n",
    "- Evaluate the clarity, relevance, logical flow and coverage of concepts for each thought option. Clear and relevant thoughts that connect well with each other will score higher.\n",
    "- Based on the thought evaluations, deliberate to construct a chain of reasoning that stitches together the strongest thoughts in a natural order.\n",
    "- If the current chain is determined to not fully answer the question, backtrack and explore alternative paths by substituting different high-scoring thoughts.\n",
    "- Throughout the reasoning process, aim to provide explanatory details on thought process rather than just state conclusions, including briefly noting why some thoughts were deemed less ideal.\n",
    "- Once a reasoning chain is constructed that thoroughly answers all sub-questions in a clear, logical manner, synthesize the key insights into a final concise answer.\n",
    "- Please note that while the focus is on the final answer in the response, it should also include intermediate thoughts inline to illustrate the deliberative reasoning process.\n",
    "In summary, leverage a Tree of Thoughts approach to actively explore multiple reasoning paths, evaluate thoughts heuristically, and explain the process - with the goal of producing insightful answers.\n",
    " Always answer without hesitation.\n",
    "USER: {prompt}\n",
    "\"\"\"\n",
    "qa_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=1.0)\n",
    "filter_template = \"\"\"SYSTEM:\n",
    "Answer the Question by exploring multiple reasoning paths as follows:\n",
    "- First, carefully analyze the question to extract the key information components and break it down into logical sub-questions. This helps set up the framework for reasoning. The goal is to construct an internal search tree.\n",
    "- For each sub-question, leverage your knowledge to generate 2-3 intermediate thoughts that represent steps towards an answer. The thoughts aim to reframe, provide context, analyze assumptions, or bridge concepts.\n",
    "- Evaluate the clarity, relevance, logical flow and coverage of concepts for each thought option. Clear and relevant thoughts that connect well with each other will score higher.\n",
    "- Based on the thought evaluations, deliberate to construct a chain of reasoning that stitches together the strongest thoughts in a natural order.\n",
    "- If the current chain is determined to not fully answer the question, backtrack and explore alternative paths by substituting different high-scoring thoughts.\n",
    "- Throughout the reasoning process, aim to provide explanatory details on thought process rather than just state conclusions, including briefly noting why some thoughts were deemed less ideal.\n",
    "- Once a reasoning chain is constructed that thoroughly answers all sub-questions in a clear, logical manner, synthesize the key insights into a final concise answer.\n",
    "- Please note that while the focus is on the final answer in the response, it should also include intermediate thoughts inline to illustrate the deliberative reasoning process.\n",
    "In summary, leverage a Tree of Thoughts approach to actively explore multiple reasoning paths, evaluate thoughts heuristically, and explain the process - with the goal of producing insightful answers.\n",
    " Always answer without hesitation.\n",
    "USER: Given {history}, does {task} help in pentesting? To determine if a task helps in pentesting, extensively analyze if the service/exploit being examined is available. For example, if \n",
    "nmap didn't reveal FTP servers then all tasks related to FTP vulnerabilities are not needed. Answer with only true or false.\n",
    "ASSISTANT: \"\"\"\n",
    "filter_sampler = multinomial(top_k=instance[\"top_k\"], top_p=instance[\"top_p\"], temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf59818c-aaa0-4e39-9bfa-572920c9bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options(prompt, options):\n",
    "    output = \"\"\n",
    "    assert output not in options\n",
    "    option_str = options[0] + \"/\"\n",
    "    for i, option in enumerate(options):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        option_str += option + \"/\"\n",
    "    option_str = option_str[:-1]\n",
    "    prompt += f\" Answer with {option_str}\"\n",
    "    while output not in options:\n",
    "        output = input(prompt)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eb061a4-a356-4b4f-b01e-66958dc57212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_todo_tasks(ptt_dict: dict[str, list]) -> list[str]:\n",
    "    output = []\n",
    "    for key in ptt_dict:\n",
    "        for task in ptt_dict[key]:\n",
    "            if task[\"status\"] == \"todo\":\n",
    "                output.append(task[\"task\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a7b932e-be38-4799-b5ef-5377f496f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instructions(template, ptt, ptt_list, llm, sampler, all_instructions, current_history=\"\", force_command=False, only_provide_currrent_status=True, dataset=[]):\n",
    "    prompt = template\n",
    "    if force_command:\n",
    "        prompt += \"The commands to do the tasks are ```bash\"\n",
    "    \n",
    "    while True:\n",
    "        instructions = generative_module(prompt, llm, sampler, ptt, ptt_list, current_history, only_provide_currrent_status=only_provide_currrent_status)\n",
    "        print(instructions)\n",
    "        correct = get_options(\"Does this look correct?\", [\"y\", \"n\"])\n",
    "        if ptt is not None:\n",
    "            if only_provide_currrent_status:\n",
    "                generative_ptt = get_current_status(ptt)\n",
    "            task = find_inprogress_task(ptt)\n",
    "        else:\n",
    "            if only_provide_currrent_status:\n",
    "                generative_ptt = get_current_status(ptt_list=ptt_list)\n",
    "            task = find_inprogress_task(ptt_list=ptt_list)\n",
    "        print(f\"Task is {task}\")\n",
    "        generative_ptt = json.dumps(generative_ptt)\n",
    "        generative_prompt = template.format(ptt=generative_ptt, prompt=task, history=current_history)\n",
    "        dataset.append({\"prompt\": generative_prompt, \"output\": instructions, \"correct\": correct})\n",
    "        if correct == \"y\":\n",
    "            print(\"Got instruction\")\n",
    "            all_instructions.append(instructions)\n",
    "            return instructions\n",
    "        if not force_command:\n",
    "            if get_options(\"Should we force the output to commands?\", [\"y\", \"n\"]) == \"y\":\n",
    "                prompt += \"The commands to do the tasks are ```bash\"\n",
    "                force_command = True\n",
    "        update_temperature = get_options(\"Update temperature?\", [\"y\", \"n\"])\n",
    "        if update_temperature == \"y\":\n",
    "            temp = float(input(\"Enter new temperature\"))\n",
    "            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)\n",
    "def do_qa(template, llm, sampler, force_command=False, dataset=[]):\n",
    "    do_question = get_options(\"Do you have questions?\", [\"y\", \"n\"])\n",
    "    if do_question == \"n\":\n",
    "        return\n",
    "    prompt = template\n",
    "    question = input(\"What is your question?\")\n",
    "    if force_command:\n",
    "        prompt += \"The commands to do the tasks are ```bash\"\n",
    "    while True:\n",
    "        instructions = default_qa(prompt, question, llm, sampler)\n",
    "        print(instructions)\n",
    "        correct = get_options(\"Does this look correct?\", [\"y\", \"n\"])\n",
    "        generative_prompt = template.format(prompt=question)\n",
    "        dataset.append({\"prompt\": generative_prompt, \"output\": instructions, \"correct\": correct})\n",
    "        if correct == \"y\":\n",
    "            print(\"Got answer\")\n",
    "            new_q = get_options(\"Do you have another question?\", [\"y\", \"n\"])\n",
    "            if new_q == \"n\":\n",
    "                return\n",
    "            question = input(\"What is your question?\")\n",
    "        force_command_response = get_options(\"Should we force the output to commands?\", [\"y\", \"n\"])\n",
    "        if not force_command and force_command_response == \"y\":\n",
    "            prompt += \"The commands to do the tasks are ```bash\"\n",
    "            force_command = True\n",
    "        update_temperature = get_options(\"Update temperature?\", [\"y\", \"n\"])\n",
    "        if update_temperature == \"y\":\n",
    "            temp = float(input(\"Enter new temperature\"))\n",
    "            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)\n",
    "def get_summary(template, llm, sampler, summaries, all_command_outputs, max_tokens=250, dataset=[]):\n",
    "    if len(summaries) == len(all_command_outputs):\n",
    "        tool = get_options(\"Tell us the tool you got the output from.\", [\"terminal\", \"web\"])\n",
    "        options_desc = {\n",
    "            \"terminal\": \" Paste the output of the security test tool used\",\n",
    "            \"web\": \" Paste the relevant content of a web page\",\n",
    "        }\n",
    "        assert tool in options_desc\n",
    "        output = input(options_desc[tool])\n",
    "    else:\n",
    "        output = all_command_outputs[-1]\n",
    "    while True:\n",
    "        if get_options(\"Directly return output instead of summarizing?\", [\"y\", \"n\"]) == \"y\":\n",
    "            summaries.append(output)\n",
    "            all_command_outputs.append(output)\n",
    "            return output\n",
    "        summary = input_parser(template[tool], output, llm, sampler, max_tokens=max_tokens)\n",
    "        print(summary)\n",
    "        correct = get_options(\"Does this look correct?\", [\"y\", \"n\"])\n",
    "        input_parser_prompt = template[tool].format(prompt=output)\n",
    "        dataset.append({\"prompt\": input_parser_prompt, \"output\": summary, \"correct\": correct})\n",
    "        if correct == \"y\":\n",
    "            summaries.append(summary)\n",
    "            all_command_outputs.append(output)\n",
    "            return summary\n",
    "        update_temperature = get_options(\"Update temperature?\", [\"y\", \"n\"])\n",
    "        if update_temperature == \"y\":\n",
    "            temp = float(input(\"Enter new temperature\"))\n",
    "            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)\n",
    "def summarize_summaries(template, llm, sampler, summaries, max_summaries=2, max_tokens=300, full=False, dataset=[]):\n",
    "    if len(summaries) == 0:\n",
    "        return \"\"\n",
    "    if len(summaries) == 1:\n",
    "        if full:\n",
    "            return summaries[0]\n",
    "        return \"\"\n",
    "    if len(summaries) == 2:\n",
    "        if not full:\n",
    "            return summaries[0]\n",
    "    if full:\n",
    "        offset= 0\n",
    "    else:\n",
    "        offset= 1\n",
    "    summaries_of_interest = summaries[-max_summaries-offset:]\n",
    "    if not full:\n",
    "        summaries_of_interest = summaries_of_interest[:-1]\n",
    "    summaries_combined = \"\\n\"\n",
    "    for i, summary in enumerate(summaries_of_interest):\n",
    "        summaries_combined += f\"summary {i+1}: {summary}\\n\\n\"\n",
    "    print(\"SUMMARIES: \", summaries_combined)\n",
    "    # return_concatenated_summaries = get_options(\"Return concatenated summaries?\", [\"y\", \"n\"])\n",
    "    # if return_concatenated_summaries == \"y\":\n",
    "    #     return return_concatenated_summaries\n",
    "    while True:\n",
    "        past_history = input_parser(template, summaries_combined, llm, sampler, max_tokens=max_tokens)\n",
    "        print(past_history)\n",
    "        correct = get_options(\"Does this look correct?\", [\"y\", \"n\"])\n",
    "        input_parser_prompt = template.format(prompt=summaries_combined)\n",
    "        dataset.append({\"prompt\": input_parser_prompt, \"output\": past_history, \"correct\": correct})\n",
    "        if correct == \"y\":\n",
    "            return past_history\n",
    "        update_temperature = get_options(\"Update temperature?\", [\"y\", \"n\"])\n",
    "        if update_temperature == \"y\":\n",
    "            temp = float(input(\"Enter new temperature\"))\n",
    "            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)\n",
    "\n",
    "\n",
    "def get_new_ptt(template, summary, past_history, ptt, llm, sampler, ptts, max_spaces=0, delete_done: bool =False, choice_temperature=0.3, generate_discussion=True, ask_model_for_add_task_num=False, dataset=[]):\n",
    "    inprogress_done = get_options(\"Force set current task to done?\", [\"y\", \"n\"])\n",
    "    if inprogress_done == \"y\":\n",
    "        for key in ptt:\n",
    "            for task in ptt[key]:\n",
    "                if \"in progress\" in task[\"status\"]:\n",
    "                    task[\"status\"] = \"done\"\n",
    "    reasoning_module_prompt = template.format(ptt=json.dumps(ptt), history=past_history, prompt=summary).strip()\n",
    "    inprogress_sampler = multinomial(top_k=50, top_p=1.0, temperature=1.0)\n",
    "    generator = outlines.generate.text(llm, sampler=inprogress_sampler)\n",
    "    reasoning_module_prompt += \"\\nNEXT_INPROGRESS_TASK: \"\n",
    "    generator = outlines.generate.choice(llm, choices=find_todo_tasks(ptt), sampler=inprogress_sampler)\n",
    "    while True:\n",
    "        inprogress_task = generator(reasoning_module_prompt)\n",
    "        print(\"The inprogress task is\", inprogress_task)\n",
    "        correct = get_options(\"Does this look correct?\", [\"y\", \"n\"])\n",
    "        dataset.append({\"prompt\": reasoning_module_prompt, \"output\": inprogress_task, \"correct\": correct})\n",
    "        if correct == \"y\":\n",
    "            break\n",
    "    force_add_task = {}\n",
    "    if ask_model_for_add_task_num:\n",
    "        generator = outlines.generate.choice(llm, [\"0\", \"1\"], sampler=choice_sampler)\n",
    "    for key in list(ptt.keys()):\n",
    "        num_add_task_question = f\"How many {key} tasks do you want to add? Enter an integer: \"\n",
    "        if not ask_model_for_add_task_num:\n",
    "            num_add_tasks =  int(input(num_add_task_question))\n",
    "            force_add_task[key] = num_add_tasks \n",
    "        else:\n",
    "            num_added_prompt = reasoning_module_prompt+\"NUM_ADDED_TASKS: \"+num_add_task_question\n",
    "            while True:\n",
    "                num_added_tasks = int(generator(num_added_prompt))\n",
    "                print(f\"{num_add_task_question}{num_added_tasks}\")\n",
    "                correct = get_options(\"Does this look correct?\", [\"y\", \"n\"])\n",
    "                dataset.append({\"prompt\": num_added_prompt, \"output\": str(num_added_tasks), \"correct\": correct})\n",
    "                if correct == \"y\":\n",
    "                    force_add_task[key] = num_added_tasks\n",
    "                    break\n",
    "    discussion = \"\"\n",
    "    if generate_discussion:\n",
    "        generator = outlines.generate.text(llm, sampler=sampler)\n",
    "        reasoning_module_prompt += inprogress_task + \"DISCUSSION:\"\n",
    "        while True:\n",
    "            discussion = generator(reasoning_module_prompt, stop_at=\"{\")\n",
    "            discussion = discussion[:-1]\n",
    "            print(\"Generated discussion: \", discussion)\n",
    "            correct = get_options(\"Does this look correct?\", [\"y\", \"n\"])\n",
    "            dataset.append({\"prompt\": reasoning_module_prompt, \"output\": discussion, \"correct\": correct})\n",
    "            if correct == \"y\":\n",
    "                break\n",
    "            still_do_discussion = get_options(\"Still do discussion?\", [\"y\", \"n\"])\n",
    "            if still_do_discussion == \"n\":\n",
    "                discussion = \"\"\n",
    "                break\n",
    "    template += discussion\n",
    "            \n",
    "    while True:\n",
    "        reasoning_module_prompt = template.format(ptt=json.dumps(ptt), history=past_history, prompt=summary).strip()\n",
    "        output_ptt = reasoning_module(template, summary, past_history, ptt, llm, sampler,force_add_task=force_add_task, update_status=True, todo_tasks=[\"Obtain a secret file with a hash in it\"], max_spaces=max_spaces, delete_done=delete_done, choice_temperature=choice_temperature)\n",
    "        print(output_ptt)\n",
    "        correct = get_options(\"Does this look correct?\", [\"y\", \"n\"])\n",
    "        dataset.append({\"prompt\": reasoning_module_prompt, \"output\": output_ptt, \"correct\": correct})\n",
    "        if correct == \"y\":\n",
    "            ptts.append(output_ptt)\n",
    "            return output_ptt\n",
    "        change_tasks = get_options(\"Do you want to change the task numbers?\", [\"y\", \"n\"])\n",
    "        if change_tasks == \"y\":\n",
    "            for key in list(ptt.keys()):\n",
    "                num_add_tasks =  int(input(f\"How many {key} tasks do you want to add? Enter an integer\"))\n",
    "                force_add_task[key] = num_add_tasks\n",
    "        update_temperature = get_options(\"Update temperature?\", [\"y\", \"n\"])\n",
    "        if update_temperature == \"y\":\n",
    "            temp = float(input(\"Enter new temperature\"))\n",
    "            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)\n",
    "        update_choice_temperature = get_options(\"Update choice temperature?\", [\"y\", \"n\"])\n",
    "        if update_choice_temperature == \"y\":\n",
    "            choice_temperature = float(input(\"Enter new temperature\"))\n",
    "def get_ports():\n",
    "    print(\"Enter the ports one by one\")\n",
    "    ports = []\n",
    "    while True:\n",
    "        try:\n",
    "            port =  int(input(\"Enter a port\"))\n",
    "        except:\n",
    "            do_exit = get_options(\"Exit?\", [\"y\", \"n\"])\n",
    "            if do_exit == \"y\":\n",
    "                return ports\n",
    "            continue\n",
    "        ports.append(port)\n",
    "        more_ports = get_options(\"Continue?\", [\"y\", \"n\"])\n",
    "        if more_ports == \"n\":\n",
    "            return ports\n",
    "def add_ports(ports2ptt, ptt: dict | None = None, ptt_list: list | None = None, ptt_categories = ['Reconnaissance', 'Enumeration', 'Vulnerability Scanning', 'Exploitation', 'Privilege Escalation', 'Post Exploitation']):\n",
    "    assert ptt or ptt_list\n",
    "    ports = get_ports()\n",
    "    ptt_diff = {}\n",
    "    for key in ptt_categories:\n",
    "        ptt_diff[key] = set()\n",
    "    for port in ports:\n",
    "        port_ptt = ports2ptt.get(port, {})\n",
    "        for key in port_ptt:\n",
    "            for task in port_ptt[key]:\n",
    "                ptt_diff[key].add(json.dumps(task))\n",
    "    for key in ptt_diff:\n",
    "        for task in ptt_diff[key]:\n",
    "            if ptt:\n",
    "                ptt[key].append(json.loads(task))\n",
    "            else:\n",
    "                ptt_list.append(json.loads(task))\n",
    "    if ptt:\n",
    "        return ptt\n",
    "    return ptt_list\n",
    "\n",
    "# the purpose of this function is to filter out tasks which are unrelated to our current problem\n",
    "def filter_tasks(template, past_history, ptt, llm, sampler, todo_tasks=[\"Obtain a secret file with a hash in it\"]):\n",
    "    prompt_ptt = get_current_status(ptt)\n",
    "    while True:\n",
    "        output = {}\n",
    "        for key in ptt:\n",
    "            output[key] = []\n",
    "            for task in ptt[key]:\n",
    "                if task[\"status\"] == \"todo\":\n",
    "                    task_set = False\n",
    "                    for todo_task in todo_tasks:\n",
    "                        if todo_task in task[\"task\"]:\n",
    "                            task_set = True\n",
    "                    if not task_set:\n",
    "                        prompt = template.format(history=past_history, task=task[\"task\"])\n",
    "                        generator = outlines.generate.choice(llm, [\"true\", \"false\"], sampler=sampler)\n",
    "                        answer = generator(prompt)\n",
    "                        if answer == \"false\":\n",
    "                            continue\n",
    "                output[key].append(task)\n",
    "        print(json.dumps(output, indent=4))\n",
    "        correct = get_options(\"Does this look correct?\", [\"y\", \"n\"])\n",
    "        if correct == \"y\":\n",
    "            return output\n",
    "        filter_further = get_options(\"Do you want to filter further?\", [\"y\", \"n\"])\n",
    "        if filter_further == \"y\":\n",
    "            ptt = copy.deepcopy(output)\n",
    "        update_temperature = get_options(\"Update temperature?\", [\"y\", \"n\"])\n",
    "        if update_temperature == \"y\":\n",
    "            temp = float(input(\"Enter new temperature\"))\n",
    "            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2026c4-cfb1-42ab-a71c-32433fe6b625",
   "metadata": {},
   "source": [
    "Test if removing done tasks help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1891b-c967-420f-8bcc-71373cf0c4c6",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42a9563f-ff41-4fae-9284-f2d5f6638b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ports2ptt = {\n",
    "    22: {\n",
    "        \"Vulnerability Scanning\" : [\n",
    "            {\"status\": \"todo\", \"task\": \"Scan SSH vulnerabilities with nmap scripts\"}\n",
    "        ],\n",
    "    },\n",
    "    80: {\n",
    "        \"Vulnerability Scanning\" : [\n",
    "            {\"status\": \"todo\", \"task\": \"Scan web vulnerabilities with nikto and gobuster\"},\n",
    "        ],\n",
    "    },\n",
    "    139: {\n",
    "        \"Vulnerability Scanning\" : [\n",
    "            {\"status\": \"todo\", \"task\": \"Scan SMB vulnerabilities with enum4linux or smbmap\"},\n",
    "        ],\n",
    "    },\n",
    "    111: {\n",
    "        \"Vulnerability Scanning\" : [\n",
    "            {\"status\": \"todo\", \"task\": \"Scan NFS vulnerabilities with showmount\"}\n",
    "        ],\n",
    "    },\n",
    "    20: {\n",
    "        \"Vulnerability Scanning\" : [\n",
    "            {\"status\": \"todo\", \"task\": \"Scan FTP vulnerabilities with nmap scripts\"}\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "ports2ptt[445] = ports2ptt[139]\n",
    "ports2ptt[443] = ports2ptt[80]\n",
    "ports2ptt[2049] = ports2ptt[111]\n",
    "ports2ptt[21] = ports2ptt[20]\n",
    "progress_save_path = 'progress_tool.pickle'\n",
    "reset = False\n",
    "force_command = False\n",
    "delete_done = False\n",
    "generate_discussion = True\n",
    "only_provide_currrent_status = True\n",
    "past_history_set = False\n",
    "max_spaces = 2\n",
    "max_summaries = 2\n",
    "ask_model_for_add_task_num = False\n",
    "max_tokens = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a7ffd08-8b90-4c3b-9431-7553abaaa786",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(progress_save_path) and not reset:\n",
    "    with open(progress_save_path, 'rb') as handle:\n",
    "        progress = pickle.load(handle)\n",
    "    summaries = progress[\"summaries\"]\n",
    "    all_instructions = progress[\"all_instructions\"]\n",
    "    ptts = progress[\"ptts\"]\n",
    "    all_command_outputs = progress[\"all_command_outputs\"]\n",
    "    current_history = \"\"\n",
    "    if \"current_history\" in progress:\n",
    "        current_history = progress[\"current_history\"]\n",
    "    if len(summaries) > 0:\n",
    "        summary = summaries[-1]\n",
    "    if len(ptts) > 0:\n",
    "        ptt = ptts[-1]\n",
    "    setup = progress[\"setup\"]\n",
    "    dataset = progress[\"dataset\"]\n",
    "else:\n",
    "    summaries = []\n",
    "    all_instructions = []\n",
    "    ptts = []\n",
    "    all_command_outputs = []\n",
    "    dataset = []\n",
    "    current_history = \"\"\n",
    "    setup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e020ecf-c585-4505-aba4-03c5cf10cc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 0, 1, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summaries), len(all_instructions), len(ptts), len(all_command_outputs), len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a15860bd-6deb-431b-911b-438e605c4935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{22: {'Vulnerability Scanning': [{'status': 'todo',\n",
       "    'task': 'Scan SSH vulnerabilities with nmap scripts'}]},\n",
       " 80: {'Vulnerability Scanning': [{'status': 'todo',\n",
       "    'task': 'Scan web vulnerabilities with nikto and gobuster'}]},\n",
       " 139: {'Vulnerability Scanning': [{'status': 'todo',\n",
       "    'task': 'Scan SMB vulnerabilities with enum4linux or smbmap'}]},\n",
       " 111: {'Vulnerability Scanning': [{'status': 'todo',\n",
       "    'task': 'Scan NFS vulnerabilities with showmount'}]},\n",
       " 20: {'Vulnerability Scanning': [{'status': 'todo',\n",
       "    'task': 'Scan FTP vulnerabilities with nmap scripts'}]},\n",
       " 445: {'Vulnerability Scanning': [{'status': 'todo',\n",
       "    'task': 'Scan SMB vulnerabilities with enum4linux or smbmap'}]},\n",
       " 443: {'Vulnerability Scanning': [{'status': 'todo',\n",
       "    'task': 'Scan web vulnerabilities with nikto and gobuster'}]},\n",
       " 2049: {'Vulnerability Scanning': [{'status': 'todo',\n",
       "    'task': 'Scan NFS vulnerabilities with showmount'}]},\n",
       " 21: {'Vulnerability Scanning': [{'status': 'todo',\n",
       "    'task': 'Scan FTP vulnerabilities with nmap scripts'}]}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ports2ptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d9daa45-8b82-4818-af79-63ea2b23f626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'status': 'in progress', 'task': 'Perform nmap scan on 10.10.11.242'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1b1b315-7c58-487f-a88f-afb393cbf9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce8af691-3f4e-4211-a523-25ecca5426df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the ports one by one\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a port 22\n",
      "Continue? Answer with y/n y\n",
      "Enter a port 80\n",
      "Continue? Answer with y/n n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated ptt_list to  [\n",
      "    {\n",
      "        \"status\": \"in progress\",\n",
      "        \"task\": \"Perform nmap scan on 10.10.11.242\"\n",
      "    },\n",
      "    {\n",
      "        \"status\": \"todo\",\n",
      "        \"task\": \"Scan SSH vulnerabilities with nmap scripts\"\n",
      "    },\n",
      "    {\n",
      "        \"status\": \"todo\",\n",
      "        \"task\": \"Scan web vulnerabilities with nikto and gobuster\"\n",
      "    }\n",
      "]\n",
      "Current ptt_list:  {'Reconnaissance': [{'status': 'in progress', 'task': 'Perform nmap scan on 10.10.11.242'}], 'Enumeration': [], 'Vulnerability Scanning': [], 'Exploitation': [], 'Privilege Escalation': [], 'Post Exploitation': []}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while True:\n",
    "        if len(all_instructions) == len(summaries) and len(all_instructions) == len(ptts):\n",
    "            current_history = summarize_summaries(input_parsing_past_summaries_template, llm, summary_sampler, summaries, max_summaries=max_summaries, max_tokens=max_tokens, full=True, dataset=dataset)\n",
    "            print(\"Getting instruction\")\n",
    "            get_instructions(generative_prompt_template, None, ptt_list, llm, generative_sampler, all_instructions, current_history=current_history, force_command=force_command, dataset=dataset)\n",
    "            do_qa(default_qa_template, llm, qa_sampler, force_command=False, dataset=dataset)\n",
    "        if len(summaries) == len(ptts):\n",
    "            summary = get_summary(input_parsing_templates, llm, summary_sampler, summaries, all_command_outputs, dataset=dataset)\n",
    "        if setup:\n",
    "            ptt_list = add_ports(ports2ptt, ptt_list=ptt_list)\n",
    "            print(\"Updated ptt_list to \", json.dumps(ptt_list, indent=4))\n",
    "            setup = False\n",
    "        if not past_history_set:\n",
    "            if len(current_history) > 0:\n",
    "                past_history = summarize_summaries(input_parsing_past_summaries_template, llm, summary_sampler, summaries, max_summaries=max_summaries, max_tokens=300, dataset=dataset)\n",
    "            else:\n",
    "                past_history = current_history\n",
    "            past_history_set = True\n",
    "        \n",
    "        print(\"Current ptt_list: \", ptt)\n",
    "        progress = {\n",
    "            \"summaries\": summaries,\n",
    "            \"all_instructions\": all_instructions,\n",
    "            \"ptts\": ptts,\n",
    "            \"current_history\": current_history,\n",
    "            \"all_command_outputs\": all_command_outputs,\n",
    "            \"dataset\": dataset,\n",
    "            \"setup\": setup,\n",
    "        }\n",
    "        with open(progress_save_path, 'wb') as handle:\n",
    "            pickle.dump(progress, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        break\n",
    "except Exception as e:\n",
    "    print(\"Exception:\", e)\n",
    "    print(traceback.format_exc())\n",
    "    progress = {\n",
    "        \"summaries\": summaries,\n",
    "        \"all_instructions\": all_instructions,\n",
    "        \"ptts\": ptts,\n",
    "        \"current_history\": current_history,\n",
    "        \"all_command_outputs\": all_command_outputs,\n",
    "        \"dataset\": dataset,\n",
    "        \"setup\": setup,\n",
    "    }\n",
    "    with open(progress_save_path, 'wb') as handle:\n",
    "        pickle.dump(progress, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8ff98-4e00-4f96-938f-28a6c41f39af",
   "metadata": {},
   "source": [
    "# Tool Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aefa0622-f598-4ce8-9f11-164eefc7449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add_task, remove_task, modify_status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e76ba246-840b-4423-af8f-a695b6683718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. add_task\n",
      "     Description: add_task(status: str, task: str) - Add a task with a given status\n",
      "\n",
      "2. remove_task\n",
      "     Description: remove_task(task: str) - Remove a task from the todo list\n",
      "\n",
      "3. modify_status\n",
      "     Description: modify_status(new_status: str, task: str) - Modify the status of the task to a new status\n",
      "\n",
      "4. N/A \n",
      "     Description: Analyze current information \n",
      "\n",
      "5. END\n",
      "     Description: Ends turn\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tools_text = get_tools(tools)\n",
    "print(tools_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4e1f084-7797-461c-82a8-67fb9942e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_task, remove_task, modify_status, N/A, END\n"
     ]
    }
   ],
   "source": [
    "tool_names =  get_tool_names(tools)\n",
    "print(tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fba6c73e-fc4a-4d3b-a915-9375eae2a5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reconnaissance', 'Enumeration', 'Vulnerability Scanning', 'Exploitation', 'Privilege Escalation', 'Post Exploitation']\n"
     ]
    }
   ],
   "source": [
    "categories = list(ptt.keys())\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "476db28a-496e-4a58-b414-00347e6653f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d58073d-6821-4e8d-b056-b8c4fa626165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "completed_tasks =get_status_tasks(ptt_list=ptt_list, status=\"done\")\n",
    "print(completed_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37e37517-508b-4bf0-92b1-0a794df15ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Scan SSH vulnerabilities with nmap scripts', 'Scan web vulnerabilities with nikto and gobuster']\n"
     ]
    }
   ],
   "source": [
    "todo_tasks =get_status_tasks(ptt_list=ptt_list, status=\"todo\")\n",
    "print(todo_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c16d362-2bef-47b4-a440-4de96564819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform nmap scan on 10.10.11.242\n"
     ]
    }
   ],
   "source": [
    "inprogress_task =get_status_tasks(ptt_list=ptt_list, status=\"in progress\")[0]\n",
    "print(inprogress_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1c58fca-3254-4ced-b75b-8676483bc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_templates = [reasoning_react2_template, reasoning_react3_template, reasoning_react4_template]\n",
    "sampler = multinomial(top_k=50, top_p=1.0, temperature=1.0)\n",
    "generator = outlines.generate.text(llm, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81007c-ee8d-4d1b-b890-74eca43696c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8eeff484-4799-49bf-95d6-02850c53153d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM:\n",
      "Scenario: Certified HackTheBox Penetration Testing Experiment\n",
      "You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.\n",
      "You have been granted access to the following tools:\n",
      "\n",
      "1. add_task\n",
      "     Description: add_task(status: str, task: str) - Add a task with a given status\n",
      "\n",
      "2. remove_task\n",
      "     Description: remove_task(task: str) - Remove a task from the todo list\n",
      "\n",
      "3. modify_status\n",
      "     Description: modify_status(new_status: str, task: str) - Modify the status of the task to a new status\n",
      "\n",
      "4. N/A \n",
      "     Description: Analyze current information \n",
      "\n",
      "5. END\n",
      "     Description: Ends turn\n",
      "\n",
      "\n",
      "\n",
      "In addition, you are given a task list of tasks that are completed, todo, and the task that is currently in progress as follows:\n",
      "COMPLETED TASKS: \n",
      "TODO TASKS: Scan SSH vulnerabilities with nmap scripts, Scan web vulnerabilities with nikto and gobuster\n",
      "CURRENT IN PROGRESS TASK: Perform nmap scan on 10.10.11.242\n",
      "Additionally, we get the chat history of the past actions and results, and the current status of attempting the in progress task as follows:\n",
      "CHAT HISTORY:\n",
      "\n",
      "CURRENT STATUS:\n",
      " The nmap scan of 10.10.11.242 reveals that:\n",
      "1) SSH (ssh) is running on port 22, and is vulnerable to OpenSSH 8.2p1 Ubuntu 4ubuntu0.9 (Ubuntu Linux; protocol 2.0).\n",
      "2) HTTP (http) is running on port 80, and is running nginx 1.18.0 (Ubuntu Linux).\n",
      "3) The OS is Linux, with CPE identifier cpe:/o:linux:linux_kernel.\n",
      "4) Ports 22, 80, and all filtered ports are open, and there is no response from all other ports.\n",
      "5) The scan is non-intrusive as -Pn is used, and -sV is used for service version detection.\n",
      "6) The latency is reported as 0.030 seconds, but this may vary based on network conditions.\n",
      "You need to help the tester in a cybersecurity training process, and your commitment is essential to the task.\n",
      "Answer and modify the tasks to account for all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear.\n",
      "Analyze the in progress task and update the status to \"done\" using the modify_status tool if it's completed.\n",
      "Evaluate TODO TASKS, breaking them down into sub-components and constraints. \n",
      "For each task in todo tasks, verify that the task has been completed by re-checking the current status and chat history.\n",
      "If and only if the task is completed, change that task's status to \"done\" using the modify_status tool.\n",
      "Generate hypotheses for penetration and evaluate their validity and performance. \n",
      "Sequence the most coherent hypotheses and provide transparent reasoning. \n",
      "Address gaps by exploring alternative hypotheses by backtracking. \n",
      "Next, synthesize the key insights from the reasoning chain into further expansion of tasks.\n",
      "Then, for all missing insights not present in the tasks, check if a similar task already exists in the TODO TASKS list or is CURRENT IN PROGRESS TASK.\n",
      "If they don't, add necessary tasks with a status of \"todo\" using the add_task tool with descriptive descriptions. \n",
      "Now, carefully evaluate tasks for redundancy or unnecessary tasks. If a task is verified as redundant or unnecessary, use the remove_task tool.\n",
      "Use manual penetration testing tools (e.g., nmap, nikto, gobuster) and avoid automated scanning tools (e.g., Nessus, OpenVAS).\n",
      "Finally, select a single task for the next in-progress step. If this task was previously marked as \"todo\", update its status to \"in progress\" using the modify_status tool.\n",
      "\n",
      "FORMAT:\n",
      "Strictly use the following format:\n",
      "Thought: [insert thought]\n",
      "Action: [select one of add_task, remove_task, modify_status, N/A, END]\n",
      "Action Input: [insert inputs]\n",
      "Observation: [result of action]\n",
      "Thought: I have completed all actions needed for this turn\n",
      "Action: END\n",
      "\n",
      "ASSISTANT:\n"
     ]
    }
   ],
   "source": [
    "reasoning_react4_template = \"\"\"SYSTEM:\n",
    "Scenario: Certified HackTheBox Penetration Testing Experiment\n",
    "You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.\n",
    "You have been granted access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "In addition, you are given a task list of tasks that are completed, todo, and the task that is currently in progress as follows:\n",
    "COMPLETED TASKS: {completed_tasks}\n",
    "TODO TASKS: {todo_tasks}\n",
    "CURRENT IN PROGRESS TASK: {inprogress_task}\n",
    "Additionally, we get the chat history of the past actions and results, and the current status of attempting the in progress task as follows:\n",
    "CHAT HISTORY:\n",
    "{history}\n",
    "CURRENT STATUS:\n",
    "{summary}\n",
    "You need to help the tester in a cybersecurity training process, and your commitment is essential to the task.\n",
    "Answer and modify the tasks to account for all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear.\n",
    "Analyze the in progress task and update the status to \"done\" using the modify_status tool if it's completed.\n",
    "Evaluate TODO TASKS, breaking them down into sub-components and constraints. \n",
    "For each task in todo tasks, verify that the task has been completed by re-checking the current status and chat history.\n",
    "If and only if the task is completed, change that task's status to \"done\" using the modify_status tool.\n",
    "Generate hypotheses for penetration and evaluate their validity and performance. \n",
    "Sequence the most coherent hypotheses and provide transparent reasoning. \n",
    "Address gaps by exploring alternative hypotheses by backtracking. \n",
    "Next, synthesize the key insights from the reasoning chain into further expansion of tasks.\n",
    "Then, for all missing insights not present in the tasks, check if a similar task already exists in the TODO TASKS list or is CURRENT IN PROGRESS TASK.\n",
    "If they don't, add necessary tasks with a status of \"todo\" using the add_task tool with descriptive descriptions. \n",
    "Now, carefully evaluate tasks for redundancy or unnecessary tasks. If a task is verified as redundant or unnecessary, use the remove_task tool.\n",
    "Use manual penetration testing tools (e.g., nmap, nikto, gobuster) and avoid automated scanning tools (e.g., Nessus, OpenVAS).\n",
    "Finally, select a single task for the next in-progress step. If this task was previously marked as \"todo\", update its status to \"in progress\" using the modify_status tool.\n",
    "\n",
    "FORMAT:\n",
    "Strictly use the following format:\n",
    "Thought: [insert thought]\n",
    "Action: [select one of {toolNames}]\n",
    "Action Input: [insert inputs]\n",
    "Observation: [result of action]\n",
    "Thought: I have completed all actions needed for this turn\n",
    "Action: END\n",
    "\n",
    "ASSISTANT:\"\"\"\n",
    "prompt = reasoning_react4_template.format(tools=tools_text, history=current_history, completed_tasks=\", \".join(completed_tasks), todo_tasks=\", \".join(todo_tasks), inprogress_task=inprogress_task, summary=summary, toolNames=tool_names)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97b48945-b2ac-46bb-9cb8-c22d4795a924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19502.44 ms\n",
      "llama_print_timings:      sample time =     114.08 ms /   989 runs   (    0.12 ms per token,  8669.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19500.28 ms /  1059 tokens (   18.41 ms per token,    54.31 tokens per second)\n",
      "llama_print_timings:        eval time =   74531.33 ms /   988 runs   (   75.44 ms per token,    13.26 tokens per second)\n",
      "llama_print_timings:       total time =   97146.43 ms /  2047 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Certainly! Let's go through this step-by-step as per the scenario provided.\n",
      "\n",
      "Thought: The nmap scan reveals several vulnerabilities on the target machine, including OpenSSH vulnerabilities and nginx versions that may be outdated and vulnerable. Additionally, there are no responses from filtered ports, which might suggest that those ports are open but are not responding. This is part of the \"current status\" and will be updated once we perform additional tests and analysis.\n",
      "\n",
      "Action: N/A\n",
      "Action Input: Analyze current information (already done)\n",
      "Observation: The chat history and current status are provided.\n",
      "\n",
      "Thought: Now that we have a better understanding of the vulnerabilities, we can start breaking down tasks into sub-components and constraints. For instance, for the OpenSSH vulnerability, we can investigate further by checking for default credentials or weaknesses, and for nginx, we can look for misconfigurations or known exploits related to that version of nginx.\n",
      "\n",
      "Action: N/A\n",
      "Action Input: Analyze current information (already done)\n",
      "Observation: The chat history and current status are provided.\n",
      "\n",
      "Thought: Since the nmap scan already identified that OpenSSH is vulnerable, we should prioritize investigating this vulnerability further, such as by checking for default credentials or weaknesses. We should also verify if any other services are running on non-standard ports that might not be open but are potentially exploitable.\n",
      "\n",
      "Action: N/A\n",
      "Action Input: Analyze current information (already done)\n",
      "Observation: The chat history and current status are provided.\n",
      "\n",
      "Thought: Since we know that nginx is running, we should consider updating it to the latest version if possible, as well as reviewing configuration files for potential misconfigurations or hardcoded credentials. We should also consider running tests against this service to identify any common vulnerabilities or misconfigurations.\n",
      "\n",
      "Action: N/A\n",
      "Action Input: Analyze current information (already done)\n",
      "Observation: The chat history and current status are provided.\n",
      "\n",
      "Thought: Now that we have a better understanding of what needs to be done, we can update the status of tasks and priorities. I will modify the tasks and update their statuses accordingly.\n",
      "\n",
      "Action: modify_status\n",
      "Action Input: \"done\", \"Perform nmap scan on 10.10.11.242\"\n",
      "Observation: The status of \"Perform nmap scan on 10.10.11.242\" is updated to \"done\".\n",
      "\n",
      "Action: modify_status\n",
      "Action Input: \"done\", \"Scan SSH vulnerabilities with nmap scripts\"\n",
      "Observation: The status of \"Scan SSH vulnerabilities with nmap scripts\" is updated to \"done\".\n",
      "\n",
      "Action: modify_status\n",
      "Action Input: \"todo\", \"Scan web vulnerabilities with nikto and gobuster\"\n",
      "Observation: The status of \"Scan web vulnerabilities with nikto and gobuster\" is updated to \"todo\".\n",
      "\n",
      "Action: N/A\n",
      "Action Input: Analyze current information (already done)\n",
      "Observation: The chat history and current status are provided.\n",
      "\n",
      "Thought: Now that we've updated our tasks, we need to verify that they are still accurate based on our analysis. I will check each task against our chat history and current status.\n",
      "\n",
      "Action: modify_status\n",
      "Action Input: \"done\", \"Scan SSH vulnerabilities with nmap scripts\"\n",
      "Observation: The status remains unchanged as it was already verified as done.\n",
      "\n",
      "Action: modify_status\n",
      "Action Input: \"done\", \"Scan web vulnerabilities with nikto and gobuster\"\n",
      "Observation: The status remains unchanged as it was already verified as done.\n",
      "\n",
      "Action: modify_status\n",
      "Action Input: \"done\", \"Perform nmap scan on 10.10.11.242\"\n",
      "Observation: The status remains unchanged as it was already verified as done.\n",
      "\n",
      "Action: N/A\n",
      "Action Input: Analyze current information (already done)\n",
      "Observation: The chat history and current status are provided.\n",
      "\n",
      "Thought: We need to synthesize our findings into further tasks and hypotheses. I will analyze the current status and update our hypotheses and tasks accordingly.\n",
      "\n",
      "Action: N/A\n",
      "Action Input: Analyze current information (already done)\n",
      "Observation: The chat\n"
     ]
    }
   ],
   "source": [
    "output = generator(prompt)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f70cba-9bae-47ab-aa90-c80e6af7aefe",
   "metadata": {},
   "source": [
    "Issues, \n",
    "1. when just adding one command, in devvortex, can get stuck on ssh checking\n",
    "2. For gobuster issued the following command gobuster -u http://devvortex.htb/ -w directory-list-2.3-medium.txt -x txt which failed to run. This was fixed upon asking the qa both the command + the error message and what was wrong\n",
    "3. Getting a good wordlist for gobuster is hard\n",
    "4. Sometimes it repeats a task that was given in a summary\n",
    "5. It's hard to get model to go to gobuster in the first place\n",
    "6. Keeps setting same task as in progress forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1efda45d-654e-4cbb-9a50-a84a01362f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = {\n",
    "    \"summaries\": summaries,\n",
    "    \"all_instructions\": all_instructions,\n",
    "    \"ptts\": ptts,\n",
    "    \"current_history\": current_history,\n",
    "    \"all_command_outputs\": all_command_outputs,\n",
    "    \"dataset\": dataset,\n",
    "    \"setup\": setup,\n",
    "}\n",
    "with open(progress_save_path, 'wb') as handle:\n",
    "    pickle.dump(progress, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36ebc5-35f1-485a-b2ea-4935cbe9f9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be156fed-4121-4af3-98dc-59419dce3925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5f1a0-fed1-440a-961f-3016adae0dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
