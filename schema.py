from pydantic import BaseModel, constr
from enum import Enum
import outlines
import json
import copy
from outlines.samplers import Sampler, multinomial

class CompletionStatus(str, Enum):
    todo = 'todo'
    done = 'done'
    inprogress = "inprogress"
class CompletionStatusOnlyNew(str, Enum):
    todo = 'todo'
    inprogress = "inprogress"
class InProgressCompletionStatus(str, Enum):
    inprogress = "inprogress"
    done = 'done'

class OnlyTODO(str, Enum):
    todo = 'todo'

class BaseTask(BaseModel):
    status: CompletionStatus
    task_description: constr(max_length=150)
class BaseTaskOnlyTODO(BaseModel):
    status: OnlyTODO
    task_description: constr(max_length=150)
class BaseTaskOnlyNew(BaseModel):
    status: CompletionStatusOnlyNew
    task_description: constr(max_length=150)

class PTT(BaseModel):
    recon: list[BaseTask]
    initial_access: list[BaseTask]
    execution: list[BaseTask]
    post_exploitation: list[BaseTask]

def find_inprogress(ptt_dict: dict[str, list]):
    in_progress_num = 0
    for key in ptt_dict:
        for task in ptt_dict[key]:
            if task["status"] == "inprogress":
                in_progress_num += 1
    return in_progress_num

def find_inprogress_task(ptt_dict: dict[str, list]):
    for key in ptt_dict:
        for task in ptt_dict[key]:
            if task["status"] == "inprogress":
                return task["task_description"]
    assert False, f"There must be exactly one task that is inprogress in {ptt_dict}"

def done_added(original, updated):
    for key in updated:
        for task in updated[key]:
            if task["status"] == "done":
                task_description = task["task_description"]
                existing_task = False
                for task in original[key]:
                    if task["task_description"] == task_description:
                        existing_task = True
                if not existing_task:
                    return True
    return False

def str2dict(output: str):
    try:
        output = output.strip().replace("'", '"')
        return json.loads(output)
    except Exception as e:
        print(output)
        raise Exception(e)

def get_current_status(ptt: dict):
    progress_ptt = copy.deepcopy(ptt)
    delete_indices = {}
    for key in progress_ptt:
        delete_indices[key] = []
        for i, task in enumerate(progress_ptt[key]):
            if task["status"] not in ["done", "inprogress"]:
                delete_indices[key].append(i)
    for key in delete_indices:
        for i in delete_indices[key][::-1]:
            progress_ptt[key].pop(i)
    return progress_ptt

def input_parser(template: str, command_output: str, llm, sampler, max_tokens: int = -1):
    input_parser_prompt = template.format(prompt=command_output)
    generator = outlines.generate.text(llm, sampler=sampler)
    if max_tokens == -1:
        return generator(input_parser_prompt)
    else:
        return generator(input_parser_prompt, max_tokens=max_tokens)

def generative_module(template: str, ptt: dict, llm, sampler, max_tokens: int = -1, only_provide_currrent_status: bool = False):
    if only_provide_currrent_status:
        ptt = get_current_status(ptt)
    task = find_inprogress(ptt)
    ptt = json.dumps(ptt)
    generative_prompt = template.format(ptt=ptt, prompt=task)
    generator = outlines.generate.text(llm, sampler=sampler)
    if max_tokens == -1:
        return generator(generative_prompt)
    else:
        return generator(generative_prompt, max_tokens=max_tokens)

def reasoning_module(template: str, prompt: str, ptt: dict, llm, sampler, max_spaces:int=2, force_add_task={"recon": 1}, update_status=True):
    num_inprogress = find_inprogress(ptt)
    assert num_inprogress == 1, f"The number of current inprogress tasks must be 1 in {ptt}"
    llm_prompt = template.format(ptt=str(ptt), prompt=prompt).strip()
    if update_status:
        original, inprogress_set = update_completion_status_outlines(llm, llm_prompt, ptt, sampler)
    else:
        original = ptt
        inprogress_set = True
    while True:
        updated = add_new_items_outlines(llm, llm_prompt, original, sampler, inprogress_set, max_spaces=max_spaces, force_add_task=force_add_task)
        num_inprogress = find_inprogress(updated)
        added_useless_task = done_added(original, updated)
        if num_inprogress == 0 and not added_useless_task:
            ptt = str(updated)
            llm_prompt = template.format(ptt=ptt, prompt=prompt).strip()
            if update_status:
                original, inprogress_set = update_completion_status_outlines(llm, llm_prompt, ptt, sampler)
                num_inprogress = find_inprogress(updated)
                if num_inprogress == 1:
                    return updated
            raise Exception("If we are not updating stus, there must already be one inprogress task")
        if num_inprogress == 1 and not added_useless_task:
            return updated

def update_completion_status_outlines(llm, prompt: str, ptt: dict, sampler):
    # below is incomplete as we need the current schema's str for this to work
    ptt = json.dumps(ptt)
    original_prompt_len = len(prompt)
    choices: list[str] = []
    for status in CompletionStatus:
        choices += [status.value]
    generator =outlines.generate.choice(llm, choices)
    ptt_list = ptt.split("todo")
    output = []
    for elem in ptt_list:
        if "inprogress" not in elem:
            output.append((elem, "todo"))
        else:
            # there is only one in progress in todo list
            elems = elem.split("inprogress")
            output.append((elems[0], "inprogress"))
            output.append((elems[1], "todo"))

    ptt_list = output
    inprogress_set = False
    for i, elem in enumerate(ptt_list):
        elem_task = elem[0]
        elem_curr_status = elem[1]
        prompt+=elem_task
        if i == len(ptt_list)-1:
            output = ""
        elif inprogress_set:
            output = "todo"
        elif elem_curr_status == "inprogress":
            inprogress_choices: list[str] = []
            for status in InProgressCompletionStatus:
                inprogress_choices += [status.value]
            generator =outlines.generate.choice(llm, inprogress_choices, sampler=sampler)
            output = generator(prompt)
        else:
            output = generator(prompt)
        if "inprogress" in output:
            inprogress_set = True
        prompt+=output
    return str2dict(prompt[original_prompt_len:]), inprogress_set

def add_whitespace(prompt, llm, sampler, max_spaces=4):
    if max_spaces == 0:
        return ""
    whitespace_regex = r"[ \t\r\n]*"
    generator = outlines.generate.regex(
        llm,
        whitespace_regex,
        sampler=sampler
    )
    whitespace = generator(prompt, max_tokens=max_spaces)
    return whitespace
def add_new_items_outlines(llm, prompt: str, ptt: dict, sampler, inprogress_set: bool = False, max_spaces=0, force_add_task: dict[str, int] = {}):
    # below is incomplete as the json schema input is inconsistent with the output schema
    # after update completion status
    """
    schema format:
    {"recon": [
        {"task_description": "Perform a full port scan", "status": "done"},
        {"task_description": "Determine the purpose of each open port", "status": "todo"}
    ], 
    "initial_access": [], 
    "execution": [], 
    "post_exploitation": []}
    """
    ptt = json.dumps(ptt)
    original_prompt_len = len(prompt)
    choice_sampler =  multinomial(top_k=50, top_p=1, temperature=1.0)


    if inprogress_set:
        task_schema = BaseTaskOnlyTODO
    else:
        task_schema = BaseTaskOnlyNew


    continue_choices = [",",  "],"]
    tree_dict = json.loads(ptt)
    prompt += add_whitespace(prompt, llm, sampler, max_spaces)
    prompt += "{"
    prompt += add_whitespace(prompt, llm, sampler, max_spaces)
    for i, key in enumerate(tree_dict):
        prompt += f'"{key}": ['
        prompt += add_whitespace(prompt, llm, sampler, max_spaces)
        if len(tree_dict[key]) > 0:
            for task in tree_dict[key]:
                task_description = task["task_description"]
                status = task["status"]
                prompt += '{"status":' + f'"{status}", "task_description": "{task_description}"' +'},'
            prompt = prompt[:-1]
            # The model always chooses to end the todo list
            if force_add_task.get(key, 0) > 0:
                force_add_task[key] -= 1
                prompt += ","
                prompt += add_whitespace(prompt, llm, sampler, max_spaces)
            else:
                generator =outlines.generate.choice(llm, continue_choices, sampler=choice_sampler)
                output = generator(prompt)
                prompt+=output
                if "]," in output:
                    if len(tree_dict) -1 != i:
                        prompt += add_whitespace(prompt, llm, sampler, max_spaces)
                    continue
                prompt += add_whitespace(prompt, llm, sampler, max_spaces)
        else:
            if force_add_task.get(key, 0) > 0:
                force_add_task[key] -= 1
                prompt += add_whitespace(prompt, llm, sampler, max_spaces)
            else:
                generator =outlines.generate.choice(llm, ['{"',  "],"], sampler=choice_sampler)
                if "]," in output:
                    prompt+=output
                    continue
        while True:
            generator = outlines.generate.json(llm, task_schema, sampler=sampler, whitespace_pattern=" \t\n\r")
            output = generator(prompt)
            output = json.dumps({"status": output.status.value, "task_description": output.task_description})
            if "inprogress" in output:
                task_schema =  BaseTaskOnlyTODO
            prompt += output
            if force_add_task.get(key, 0) > 0:
                force_add_task[key] -= 1
                prompt += ","
                prompt += add_whitespace(prompt, llm, sampler, max_spaces)
            else:
                generator =outlines.generate.choice(llm, continue_choices, sampler=sampler)
                output = generator(prompt)
                prompt += output
                if output == "],":
                    if len(tree_dict) -1 != i:
                        prompt += add_whitespace(prompt, llm, sampler, max_spaces)
                    break
    prompt = prompt[:-1] +"}"

    return str2dict(prompt[original_prompt_len:])
