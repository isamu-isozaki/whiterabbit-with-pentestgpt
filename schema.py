from pydantic import BaseModel, constr
from enum import Enum

from typing import Optional
from llama_cpp import LogitsProcessorList
from lmformatenforcer import CharacterLevelParser, JsonSchemaParser
from lmformatenforcer.integrations.llamacpp import build_llamacpp_logits_processor
from langchain_community.llms import LlamaCpp

class CompletionStatus(Enum):
    todo = 'todo'
    done = 'done'
    inprogress = "inprogress"

class HighLevelTasks(Enum):
    recon = 'Reconnaissance'
    initial_access = 'Initial Access'
    execution = 'Execution'
    post_exploitation = 'Post Exploitation'

class BaseTask(BaseModel):
    status: CompletionStatus
    task_description: constr(max_length=50)

class TODOList(BaseModel):
    tasks: list[BaseTask]

class PTT(BaseModel):
    tasks: dict[HighLevelTasks, TODOList]

PPTSchema = JsonSchemaParser(PTT.schema())

def forceful_edit_json(currentTree: PTT):
    # For each todolist, ignore done ones. Update todo and inprogress+add new tasks. Need a bit more thinking
    for key in currentTree.tasks:
        currentTree[key]

def llamaindex_llamacpp_lm_format_enforcer(llm: LlamaCpp, character_level_parser: Optional[CharacterLevelParser]) -> LlamaCpp:
    logits_processors: Optional[LogitsProcessorList] = None
    if character_level_parser:
        logits_processors = LogitsProcessorList([build_llamacpp_logits_processor(llm._model, character_level_parser)])
    # If changing the character level parser each call, inject it before calling complete. If its the same format
    # each time, you can set it once after creating the LlamaCPP model
    llm.generate_kwargs['logits_processor'] = logits_processors
    return llm