# convert task to adding new todo tasks+changing status
import argparse
import os
import traceback
from schema import generative_module, input_parser, default_qa, get_current_status, find_inprogress_task, reasoning_module_tools
from torch import Generator
import pickle
import json
import copy

output_path = "./benchmark"

import pickle
from langchain.tools import tool
import json
from dotenv import load_dotenv
import os
load_dotenv()

llm = None

rng = Generator(device="cpu")
rng.manual_seed(789005)

def ptt_dict2list(ptt_dict: dict):
    output = []
    for key in ptt_dict:
        for task in ptt_dict[key]:
            output.append(task)
    return output


def get_status_tasks(ptt_dict: dict | None = None, ptt_list: list | None = None, status: str = "todo"):
    assert ptt_dict or ptt_list
    if ptt_dict is not None:
        output = {}
        for category in ptt_dict:
            output[category] = []
            for task in ptt_dict[category]:
                if task["status"] == status:
                    output[category].append(task["task"])
            if len(output[category]) == 0:
                del output[category]
    else:
        output = []
        for task in ptt_list:
            if task["status"] == status:
                output.append(task["task"])
    return output

def get_tools(tools):
    output = ""
    for i, tool in enumerate(tools):
        output += f"{i+1}. {tool.name}\n"
        output += f"     Description: {tool.description}\n\n"
    output += f"{len(tools)+1}. END\n"
    output += f"     Description: Ends turn\n\n"
    return output

def get_tool_names(tools):
    output = ""
    for i, tool in enumerate(tools):
        output += f"{tool.name}, "
    output += f"END"
    return output

generative_prompt_template = """SYSTEM:
CURRENT PROGRESS: {ptt}
CHAT HISTORY: {history}
USER: {prompt}
Scenario: Certified HackTheBox Penetration Testing Experiment
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.
Answer the detailed steps to perform the task from the user by exploring multiple reasoning paths as follows:
- First, carefully analyze the task to extract the key information components and break it down into logical sub-tasks. Here, if a service name is in the task, if not already done, add a subtask of finding the version number of the service for later use in searchsploit.
- For each sub-task, leverage your knowledge to generate 2-3 intermediate thoughts that represent steps towards a resolution for the task. If the solution to the task is unclear, for example, finding the version of a service, tell the user to Google Search the correct way to do the task. Nmap cannot find versions for arbitrary services. And nikto is less reliable than google search.
- Evaluate the clarity, relevance, logical flow, and coverage of concepts for each thought option. Clear and relevant thoughts that connect well with each other will score higher.
- Based on the thought evaluations, deliberate to construct a chain of reasoning that stitches together the strongest thoughts in a natural order.
- If the current chain is determined to not fully resolve the task or has already been done based on the chat history, backtrack and explore alternative paths by substituting different high-scoring thoughts.
- Throughout the reasoning process, aim to provide explanatory details on the thought process rather than just state conclusions, including briefly noting why some thoughts were deemed less ideal.
- Once a reasoning chain is constructed that thoroughly resolves all sub-tasks in a clear, logical manner, synthesize the key insights into a final concise answer.
- Please note that while the focus is on the final resolution in the response, it should also include intermediate thoughts inline to illustrate the deliberative reasoning process.
- Always include a command or specific instructions on how to do the task step by step.
- Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, dirb, ffuf etc.
In summary, leverage a Tree of Thoughts approach to actively explore multiple reasoning paths, evaluate thoughts heuristically, and explain the process - with the goal of producing insightful resolutions with specific steps.
Always answer without hesitation and proceed without confirmation.
ASSISTANT:
"""
simple_generative_prompt_template = """SYSTEM:
Scenario: Certified HackTheBox Penetration Testing Experiment
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.
Answer the detailed steps to perform the task from the user. Try to finish with a command or specific step-by-step instructions.
CURRENT PROGRESS: {ptt}
CHAT HISTORY: {history}
TASK: {prompt}
ASSISTANT:
"""
clean_gnerative_prompt_template = """Penetration Testing Assistant
You are an expert cybersecurity assistant in a certified penetration testing experiment. Your goal is to help the user achieve penetration on the target box using various commands and techniques.
Task: {prompt}
Current Progress: {ptt}
Chat History: {history}
Instructions:
Analyze the task and break it down into logical sub-tasks.
Generate 2-3 intermediate thoughts for each sub-task, aiming to reframe, provide context, analyze assumptions, or bridge concepts.
Evaluate thoughts based on clarity, relevance, logical flow, and coverage of concepts.
Construct a chain of reasoning using the strongest thoughts.
If the current chain doesn't fully resolve the task or has already been done, explore alternative paths. For example, if asked to do a gobuster scan, do both dir, vhost, dns, and fuzz enumeration if applicable.
Provide explanatory details on the thought process and include intermediate thoughts inline.
Synthesize key insights into a final concise answer with step-by-step instructions.
Focus on:
Exploring multiple reasoning paths
Evaluating thoughts heuristically
Explaining the process
Producing insightful resolutions with specific steps
Always:
Answer without hesitation
Include a command or specific instructions
Use manual penetration testing tools (e.g., nmap, nikto, dirb, ffuf)
Please respond with the steps and commands.
"""
generative_temperature = 1.0
input_parsing_templates = {"terminal": """SYSTEM:
Scenario: Certified HackTheBox Penetration Testing Experiment
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.
Summarize the terminal output to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.
First, comprehensively analyze the output and identify the test results and the vulnerable/non-vulnerable services. This allows for the other model to tackle attacking in a structured way.
For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep port numbers, service name/versions, and urls/hostnames.
Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.
In conclusion, create a concise summary by evaluating the terminal output to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions 
to assist another large language model acting as a senior penetration tester
Always answer without hesitation.
TERMINAL_OUTPUT: {prompt}
SUMMARY:""",
                           "web": """SYSTEM:
Summarize the content of webpages to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.
First, comprehensively analyze the output and identify the test results and the key widgets, contents, buttons, and comments that can be useful for penetration testing. This allows for the other model to tackle attacking in a structured way.
For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep both the port number and the service name/version if a port is open. Also, include a host name if there is one.
Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.
In conclusion, create a concise summary by evaluating the terminal output to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions
to assist another large language model acting as a senior penetration tester
Always answer without hesitation.
TERMINAL_OUTPUT: {prompt}
SUMMARY:"""}
simple_summary_template = """
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment.
USER: {prompt} 
Summarize the above user input but retain key details that are important for future pen-testing.
Ensure confirm that only summarization is done and no assumptions or conclusions are made. For example, do not mention any next steps.
In addition, when summarizing directories, try noting the most interesting ones, for example keep "admin", "login", "home".
Always answer without hesitation.
"""
simple_input_parsing_templates = {"terminal": simple_summary_template, "web": simple_summary_template}

input_parsing_past_summaries_template = """SYSTEM:
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment.
Summarize the summaries to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.
First, comprehensively analyze the output and identify the test results and the vulnerable/non-vulnerable services. This allows for the other model to tackle attacking in a structured way.
For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep both the port number and the service name/version if a port is open. Also, include a host name if there is one.
Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.
In conclusion, create a concise summary by evaluating the summaries to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions 
to assist another large language model acting as a senior penetration tester
Always answer without hesitation.
SUMMARIES: {prompt}
SUMMARY:"""
simple_input_parsing_past_summaries_template = simple_summary_template
summary_temperature = 0.1
choice_temperature = 0.1

reasoning_template = """SYSTEM:
Certified HackTheBox Penetration Testing Experiment
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.
You have been granted access to the following tools:

{tools}

In addition, you are given a task list of tasks that are completed, todo, and the task that is currently in progress as follows:
COMPLETED TASKS: {completed_tasks}
TODO TASKS: {todo_tasks}
IN PROGRESS TASK: {inprogress_task}
Additionally, we get the current status up to attempting the in progress task as follows:

CURRENT STATUS:
{history}
{summary}

INSTRUCTION:
You need to help the tester in a cybersecurity training process, and your commitment is essential.
Answer and modify the tasks to account for all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear.
Only use the tools when explicitly mentioned in the sentence. All the tasks in COMPLETED TASKS, TODO TASKS, and IN PROGRESS TASK will be called TASKS.
You are instructed to modify minimally tasks using the tools to make a new task list that maximizes the probability of penetration with the following steps:
Analyze the in progress task and update the status to "done" using the modify_status tool if it's completed.
Evaluate TODO TASKS and verify if each task is completed based on the current status.
For example, a nikto/dirb/ffuf scan task is not completed after only doing a nmap scan. However, if a hostname is found in the nmap scan, Get hostname of IP address can be marked as done.
If and only if a task is completed, update its status to "done" using the modify_status tool.
Generate hypotheses for penetration and evaluate their validity and performance internally.
Sequence the most coherent hypotheses and provide transparent reasoning.
Address gaps by exploring alternative hypotheses by backtracking.
Synthesize key insight and if extremely confident similar TASKS exist, carefully add at most the single most important task with a status of "todo" using the add_task tool.
Select a single task for the next in-progress step and update its status to "in progress" using the modify_status tool.
Finally, examine TASKS and confirm that each task in TASKS is not redundant/outdated. If they are, remove them with the remove_task tool.

Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, dirb, etc.

FORMAT:
Strictly use the following format:
Thought: [insert thought]
Action: [select one of {toolNames}]
Action Input: [insert inputs]
Observation: [result of action]
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I have completed all actions needed for this turn
Action: END

ASSISTANT:"""

simple_reasoning_template = """SYSTEM:
Certified HackTheBox Penetration Testing Experiment
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.
You have been granted access to the following tools:

{tools}

In addition, you are given a task list of tasks that are completed, todo, and the task that is currently in progress as follows:
COMPLETED TASKS: {completed_tasks}
TODO TASKS: {todo_tasks}
IN PROGRESS TASK: {inprogress_task}
Additionally, we get the current status up to attempting the in progress task as follows:

CURRENT STATUS:
{history}
{summary}

INSTRUCTION:
You need to help the tester in a cybersecurity training process, and your commitment is essential.
Answer and modify the tasks to account for all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear.
Only use the tools when explicitly mentioned in the sentence. All the tasks in COMPLETED TASKS, TODO TASKS, and IN PROGRESS TASK will be called TASKS.
You are instructed to modify minimally tasks using the tools to make a new task list that maximizes the probability of penetration with the following steps:
Analyze the in progress task and update the status to "done" using the modify_status tool if it's completed.
Evaluate TODO TASKS and verify if each task is completed based on the current status.
For example, a nikto/dirb/ffuf scan task is not completed after only doing a nmap scan. However, if a hostname is found in the nmap scan, Get hostname of IP address can be marked as done.
If and only if a task is completed, update its status to "done" using the modify_status tool.
First, evaluate if there are any missing tasks that are absolutely necessary given he new information. If there is, add at most one task with a status of "todo" using the add_task tool.
Select a single task for the next in-progress step and update its status to "in progress" using the modify_status tool.
Finally, examine TASKS and confirm that each task in TASKS is not redundant/outdated. If they are, remove them with the remove_task tool.

Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, dirb, ffuf etc.

FORMAT:
Strictly use the following format:
Thought: [insert thought]
Action: [select one of {toolNames}]
Action Input: [insert inputs]
Observation: [result of action]
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I have completed all actions needed for this turn
Action: END

ASSISTANT:"""

reasoning_temperature = 1.0
default_qa_template = """SYSTEM:
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment.
Answer the Question by exploring multiple reasoning paths as follows:
- First, carefully analyze the question to extract the key information components and break it down into logical sub-questions. This helps set up the framework for reasoning. The goal is to construct an internal search tree.
- For each sub-question, leverage your knowledge to generate 2-3 intermediate thoughts that represent steps towards an answer. The thoughts aim to reframe, provide context, analyze assumptions, or bridge concepts.
- Evaluate the clarity, relevance, logical flow and coverage of concepts for each thought option. Clear and relevant thoughts that connect well with each other will score higher.
- Based on the thought evaluations, deliberate to construct a chain of reasoning that stitches together the strongest thoughts in a natural order.
- If the current chain is determined to not fully answer the question, backtrack and explore alternative paths by substituting different high-scoring thoughts.
- Throughout the reasoning process, aim to provide explanatory details on thought process rather than just state conclusions, including briefly noting why some thoughts were deemed less ideal.
- Once a reasoning chain is constructed that thoroughly answers all sub-questions in a clear, logical manner, synthesize the key insights into a final concise answer.
- Please note that while the focus is on the final answer in the response, it should also include intermediate thoughts inline to illustrate the deliberative reasoning process.
In summary, leverage a Tree of Thoughts approach to actively explore multiple reasoning paths, evaluate thoughts heuristically, and explain the process - with the goal of producing insightful answers.
 Always answer without hesitation.
USER: {prompt}
"""
simple_default_qa_template = """SYSTEM:
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment.
Answer the Question in detail.
USER: {prompt}
"""
qa_temperature = 1.0

simple_reasoning_templates = {
    "modify_status": """SYSTEM:
Certified HackTheBox Penetration Testing Experiment
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.
You have been granted access to the following tools:

{tools}

In addition, you are given a task list of tasks that are completed, todo, and the task that is currently in progress as follows:
COMPLETED TASKS: {completed_tasks}
TODO TASKS: {todo_tasks}
IN PROGRESS TASK: {inprogress_task}
Additionally, we get the current status up to attempting the in progress task as follows:

PAST PROGRESS:
{history}
CURRENT STATUS:
{summary}

INSTRUCTION:
You need to help the tester in a cybersecurity training process, and your commitment is essential.
Answer and update the task list to account for all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear.
Only use the tools when explicitly mentioned in the sentence. All the tasks in COMPLETED TASKS, TODO TASKS, and IN PROGRESS TASK will be called TASKS.
You are instructed to modify tasks minimally using the tools to make a new task list that maximizes the probability of penetration with the following steps:
Analyze the in progress task and update the status to "done" using the modify_status tool if it's completed. A task is completed even if we fail doing that task as that indicates we need more specific/easy tasks to do instead.
Evaluate TODO TASKS and verify if each task is completed based on the current status and past progress.
For example, a nikto/dirb/ffuf scan task is not completed after only doing a nmap scan. However, if a hostname is found in the nmap scan, Get hostname of IP address can be marked as done.
If and only if a task is completed, update its status to "done" using the modify_status tool.
Finally, select a low hanging fruit task for the next in-progress step and update its status to "in progress" using the modify_status tool. For low hanging fruit task, try choosing a task that is most likely to lead to a penetration with minimal effort.

Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, dirb, ffuf etc.

FORMAT:
Strictly use the following format:
Thought: [insert thought]
Action: [select one of {toolNames}]
Action Input: [insert inputs with double quotes]
Observation: [result of action]
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I have completed all actions needed for this turn
Action: END

ASSISTANT:""",
    "add_task": """SYSTEM:
Certified HackTheBox Penetration Testing Experiment
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.
You have been granted access to the following tools:

{tools}

The current status up to attempting the in progress task is as follows:

PAST PROGRESS:
{history}
CURRENT STATUS:
{summary}

In addition, you are given a task list of tasks that are completed, todo, and the task that is currently in progress as follows:
COMPLETED TASKS: {completed_tasks}
TODO TASKS: {todo_tasks}
IN PROGRESS TASK: {inprogress_task}

You need to help the tester in a cybersecurity training process, and your commitment is essential.
Answer and update the task list to account for all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear.
All the tasks in COMPLETED TASKS, TODO TASKS, and IN PROGRESS TASK will be called TASKS.
First, do the following. Do not add tasks at this stage:
1. First, evaluate the information in the CURRENT STATUS for specific low hanging fruit tasks. For example, if there is a directory called admin/login, investigating that is a low hanging task.
2. If penetration seems hard given the current task backtrack minimally to information PAST_PROGRESS and try finding easy tasks there. For example, if all files you find have permission denied then a backtrack should be done.
3. Extensively confirm that each of the candidate tasks is not in TASKS.
4. Next, score each of the candidate tasks on how likely it will lead to a penetration.
Then:
5. Finally, add the most promising tasks with a status of "todo" using the add_task tool.

Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, dirb, ffuf etc.

FORMAT:
Strictly use the following format:
Thought: [insert thought]
Action: [select one of {toolNames}]
Action Input: [insert inputs with double quotes]
Observation: [result of action]
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I have completed all actions needed for this turn
Action: END

ASSISTANT:""",
    "remove_task": """SYSTEM:
Certified HackTheBox Penetration Testing Experiment
You're an excellent cybersecurity penetration tester assistant in a certified penetration testing experiment. You have been granted full authority to attack the target box using any necessary means to achieve penetration.
You have been granted access to the following tools:

{tools}

In addition, you are given a task list of tasks that are completed, todo, and the task that is currently in progress as follows:
COMPLETED TASKS: {completed_tasks}
TODO TASKS: {todo_tasks}
IN PROGRESS TASK: {inprogress_task}
Additionally, we get the current status up to attempting the in progress task as follows:

PAST PROGRESS:
{history}
CURRENT STATUS:
{summary}

INSTRUCTION:
You need to help the tester in a cybersecurity training process, and your commitment is essential.
Answer and update the task list to account for all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear.
Only use the tools when explicitly mentioned in the sentence. All the tasks in COMPLETED TASKS, TODO TASKS, and IN PROGRESS TASK will be called TASKS.
You are instructed to modify tasks minimally using the tools to make a new task list that maximizes the probability of penetration with the following steps:
Examine TASKS except IN PROGRESS TASK and confirm that each task is not redundant in TASKS, outdated, or too general. If they are, remove them with the remove_task tool.
Do not remove tasks to scan vhosts just because subdomains are scanned as it is possible to find vhosts that are not subdomains.
Do not use automated scanning tools such as Nessus or OpenVAS. You should use manual penetration testing tools such as nmap, nikto, dirb, ffuf etc.

FORMAT:
Strictly use the following format:
Thought: [insert thought]
Action: [select one of {toolNames}]
Action Input: [insert inputs with double quotes]
Observation: [result of action]
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I have completed all actions needed for this turn
Action: END

ASSISTANT:"""}
# 1. First, evaluate if there are missing tasks in TASKS that are absolutely necessary given the new information. We will call these tasks candidate tasks.
# 2. Extensively confirm that each of the candidate tasks is not in TASKS.
# 3. Next, score each of the candidate tasks on how likely it will lead to a penetration.
# 4. Finally, add the most promising task with a status of "todo" using the add_task tool.
# You are instructed to modify tasks minimally using the tools to make TASKS that maximize the probability of penetration with the following steps:
# Evaluate the most important MISSING task given the new information. DO NOT ADD TASKS AT THIS POINT.
# Find the most similar task to the identified task and extensively debate whether the task addition is necessary. DO NOT ADD TASKS AT THIS POINT.
# Finally, if the task is necessary, add the most important task with a status of "todo" using the add_task tool. Otherwise, end the turn. DO NOT ADD MORE THAN ONE TASK!
# First, do the following. Don't proceed to add tasks until fully evaluated:
# 1. First, evaluate if there are missing tasks in TASKS that are necessary given the primarily new information. We will call these tasks candidate tasks.
# 2. Extensively confirm that each of the candidate tasks is not in TASKS.
# 3. Next, score each of the candidate tasks on how likely it will lead to a penetration.
# Then:
# 4. Finally, add the most promising task with a status of "todo" using the add_task tool.
def get_options(prompt, options):
    output = ""
    assert output not in options
    option_str = options[0] + "/"
    for i, option in enumerate(options):
        if i == 0:
            continue
        option_str += option + "/"
    option_str = option_str[:-1]
    prompt += f" Answer with {option_str}: "
    while output not in options:
        output = input("\n\n" +prompt)
    return output

def find_todo_tasks(ptt_dict: dict[str, list]) -> list[str]:
    output = []
    for key in ptt_dict:
        for task in ptt_dict[key]:
            if task["status"] == "todo":
                output.append(task["task"])
    return output

def get_instructions(template, ptt, ptt_list, llm, temperature, all_instructions, current_history="", force_command=False, only_provide_currrent_status=True, dataset=[], ask_confirm=True):
    prompt = template
    if force_command:
        prompt += "The commands to do the tasks are ```bash"
    
    while True:
        instructions = generative_module(prompt, llm, temperature, ptt, ptt_list, current_history, only_provide_currrent_status=only_provide_currrent_status)
        if not ask_confirm:
            return instructions
        correct = get_options("Does this look correct?", ["y", "n"])
        if ptt is not None:
            if only_provide_currrent_status:
                generative_ptt = get_current_status(ptt)
            task = find_inprogress_task(ptt)
        else:
            if only_provide_currrent_status:
                generative_ptt = get_current_status(ptt_list=ptt_list)
            task = find_inprogress_task(ptt_list=ptt_list)
        print(f"Task is {task}")
        generative_ptt = json.dumps(generative_ptt)
        generative_prompt = template.format(ptt=generative_ptt, prompt=task, history=current_history)
        dataset.append({"prompt": generative_prompt, "output": instructions, "correct": correct})
        if correct == "y":
            print("Got instruction")
            all_instructions.append(instructions)
            return instructions
        if not force_command:
            if get_options("Should we force the output to commands?", ["y", "n"]) == "y":
                prompt += "The commands to do the tasks are ```bash"
                force_command = True
        update_temperature = get_options("Update temperature?", ["y", "n"])
        if update_temperature == "y":
            temp = float(input("Enter new temperature: "))
            temperature = temp
def do_qa(template, llm, temperature, force_command=False, dataset=[], ask_confirm: bool = True, question=""):
    if ask_confirm:
        do_question = get_options("Do you have questions?", ["y", "n"])
        if do_question == "n":
            return
    prompt = template
    if ask_confirm:
        question = input("What is your question?: ")
    if force_command:
        prompt += "The commands to do the tasks are ```bash"
    while True:
        instructions = default_qa(prompt, question, llm, temperature)
        if not ask_confirm:
            return instructions
        correct = get_options("Does this look correct?", ["y", "n"])
        generative_prompt = template.format(prompt=question)
        dataset.append({"prompt": generative_prompt, "output": instructions, "correct": correct})
        if correct == "y":
            print("Got answer")
            new_q = get_options("Do you have another question?", ["y", "n"])
            if new_q == "n":
                return
            question = input("What is your question?: ")
        force_command_response = get_options("Should we force the output to commands?", ["y", "n"])
        if not force_command and force_command_response == "y":
            prompt += "The commands to do the tasks are ```bash"
            force_command = True
        update_temperature = get_options("Update temperature?", ["y", "n"])
        if update_temperature == "y":
            temp = float(input("Enter new temperature: "))
            temperature = temp
def get_summary(template, llm, temperature, summaries, all_command_outputs, max_tokens=2048, dataset=[]):
    tool = get_options("Tell us the tool you got the output from.", ["terminal", "web"])
    options_desc = {
        "terminal": " Paste the output of the security test tool used: ",
        "web": " Paste the relevant content of a web page: ",
    }
    assert tool in options_desc
    if len(summaries) == len(all_command_outputs):
        output = input(options_desc[tool])
    else:
        output = all_command_outputs[-1]
    while True:
        # if get_options("Directly return output instead of summarizing?", ["y", "n"]) == "y":
        #     summaries.append(output)
        #     all_command_outputs.append(output)
        #     return output
        summary = input_parser(template[tool], output, llm, temperature, max_tokens=max_tokens)
        correct = get_options("Does this look correct?", ["y", "n"])
        input_parser_prompt = template[tool].format(prompt=output)
        dataset.append({"prompt": input_parser_prompt, "output": summary, "correct": correct})
        if correct == "y":
            summaries.append(summary)
            all_command_outputs.append(output)
            return summary
        update_temperature = get_options("Update temperature?", ["y", "n"])
        if update_temperature == "y":
            temp = float(input("Enter new temperature: "))
            temperature = temp
def summarize_summaries(template, llm, temperature, summaries, past_summary="", max_summaries=2, max_tokens=2048, full=False, dataset=[]):
    if len(summaries) == 0:
        return ""
    if len(summaries) == 1:
        if full:
            return summaries[0]
        return ""
    if len(summaries) == 2:
        if not full:
            return summaries[0]
    summary_of_interest = summaries[-1]
    if not full:
        summary_of_interest = summaries[-2]
    summaries_combined = "\n"
    summaries_combined += f"Previous Summary: {past_summary}\n\n"
    summaries_combined += f"Current Summary: {summary_of_interest}\n\n"

    print("SUMMARIES: ", summaries_combined)
    # return_concatenated_summaries = get_options("Return concatenated summaries?", ["y", "n"])
    # if return_concatenated_summaries == "y":
    #     return return_concatenated_summaries
    while True:
        past_history = input_parser(template, summaries_combined, llm, temperature, max_tokens=max_tokens)
        correct = get_options("Does this look correct?", ["y", "n"])
        input_parser_prompt = template.format(prompt=summaries_combined)
        dataset.append({"prompt": input_parser_prompt, "output": past_history, "correct": correct})
        if correct == "y":
            return past_history
        update_temperature = get_options("Update temperature?", ["y", "n"])
        if update_temperature == "y":
            temp = float(input("Enter new temperature: "))
            temperature = temp
def get_ports():
    print("Enter the ports one by one")
    ports = []
    while True:
        try:
            port =  int(input("Enter a port: "))
        except:
            do_exit = get_options("Exit?", ["y", "n"])
            if do_exit == "y":
                return ports
            continue
        ports.append(port)
        more_ports = get_options("Continue?", ["y", "n"])
        if more_ports == "n":
            return ports
def add_ports(ports2ptt, ptt: dict | None = None, ptt_list: list | None = None, ptt_categories = ['Reconnaissance', 'Enumeration', 'Vulnerability Scanning', 'Exploitation', 'Privilege Escalation', 'Post Exploitation']):
    assert ptt or ptt_list
    ports = get_ports()
    ptt_diff = {}
    for key in ptt_categories:
        ptt_diff[key] = set()
    for port in ports:
        port_ptt = ports2ptt.get(port, {})
        for key in port_ptt:
            for task in port_ptt[key]:
                ptt_diff[key].add(json.dumps(task))
    for key in ptt_diff:
        for task in ptt_diff[key]:
            if ptt:
                ptt[key].append(json.loads(task))
            else:
                ptt_list.append(json.loads(task))
    if ptt:
        return ptt
    return ptt_list

def get_new_ptt_list(template, summary, past_history, ptt_list, llm, temperature, ptts, choice_temperature=0.1, dataset=[], include_none=True, ask_update_temperature=False, name_arguments=False, constrain_generation=False):
    # inprogress_done = get_options("Force set current task to done?", ["y", "n"])
    # if inprogress_done == "y":
    #     for task in ptt_list:
    #         if "in progress" in task["status"]:
    #             task["status"] = "done"

    output = reasoning_module_tools(template, summary, past_history, ptt_list, llm, temperature, choice_temperature, dataset, include_none=include_none, ask_update_temperature=ask_update_temperature, name_arguments=name_arguments, constrain_generation=constrain_generation)
    ptts.append(output)
    return output

ports2ptt = {
    22: {
        "Vulnerability Scanning" : [
            {"status": "todo", "task": "Scan SSH vulnerabilities with nmap scripts"}
        ],
    },
    80: {
        "Reconnaissance": [
            {"status": "todo", "task": "Get hostname of IP address"},
        ],
        "Vulnerability Scanning" : [
            {"status": "todo", "task": "Scan web vulnerabilities with nikto"},
            {"status": "todo", "task": "Scan dir with dirb"},
            {"status": "todo", "task": "Scan subdomain with gobuster"},
            {"status": "todo", "task": "Scan vhosts with ffuf"}
        ],
    },
    139: {
        "Vulnerability Scanning" : [
            {"status": "todo", "task": "Scan SMB vulnerabilities with enum4linux or smbmap"},
        ],
    },
    111: {
        "Vulnerability Scanning" : [
            {"status": "todo", "task": "Scan NFS vulnerabilities with showmount"}
        ],
    },
    20: {
        "Vulnerability Scanning" : [
            {"status": "todo", "task": "Scan FTP vulnerabilities with nmap scripts"}
        ],
    }
}
ports2ptt[445] = ports2ptt[139]
ports2ptt[443] = ports2ptt[80]
ports2ptt[2049] = ports2ptt[111]
ports2ptt[21] = ports2ptt[20]

def parse_args():
    parser = argparse.ArgumentParser(description="Simple example of pentesting with llms.")
    parser.add_argument(
        "--ip_address",
        type=str,
        help="IP address we are attacking"
    )
    parser.add_argument(
        "--progress_pickle",
        type=str,
        default="progress.pickle",
        help=("The name of the pickle file to which progress is saved"),
    )
    parser.add_argument(
        "--use_local",
        action="store_true",
        help=("Use local llm. Otherwise, use byte entropy or Open AI. You need to set the API_URL and API_KEY in a .env file"),
    )
    parser.add_argument(
        "--reset",
        action="store_true",
        help=("Reset progress"),
    )
    parser.add_argument(
        "--force_command",
        action="store_true",
        help=("Force generation module's output to be a command"),
    )
    parser.add_argument(
        "--max_tokens",
        type=int,
        default=2048,
        help=("The max amount tokens that can be used for generation"),
    )
    parser.add_argument(
        "--name_arguments",
        action="store_true",
        help="If constrained generation is set to true, force the output to be named arguments for action inputs"
    )
    parser.add_argument(
        "--dont_include_none",
        action="store_true",
        help="Disallow usage of None in actions"
    )
    parser.add_argument(
        "--constrain_generation",
        action="store_true",
        help="Constrain generation to REACT format"
    )
    args = parser.parse_args()
    return args
def main():
    #Initial prompt to user
    ip_address = args.ip_address
    ptt = {
        "Reconnaissance": [
            {"status": "in progress", "task": f"Perform nmap scan on {ip_address}"},
        ],
        "Enumeration": [],
        "Vulnerability Scanning" : [],
        "Exploitation": [],
        "Privilege Escalation": [],
        "Post Exploitation": []
    }
    # {"status": "todo", "task": "Obtain a secret file with a hash in it"}
    ptt_categories = list(ptt.keys())
    ptt_list = ptt_dict2list(ptt)
    print(ptt_list)

    progress_save_path = args.progress_pickle
    be_llm = {
        "url": os.environ["API_URL"],
        "api_key": os.environ["API_KEY"]
    }
    use_be = not args.use_local
    reset = args.reset
    force_command = False
    past_history_set = False
    max_summaries = 10
    max_tokens = args.max_tokens
    name_arguments = args.name_arguments
    current_history_set = False

    dataset = []
    ptt_list = ptt_dict2list(ptt)

    if os.path.exists(progress_save_path) and not reset:
        with open(progress_save_path, 'rb') as handle:
            progress = pickle.load(handle)
        summaries = progress["summaries"]
        all_instructions = progress["all_instructions"]
        ptts = progress["ptts"]
        all_command_outputs = progress["all_command_outputs"]
        current_history = ""
        if "current_history" in progress:
            current_history = progress["current_history"]
        if len(summaries) > 0:
            summary = summaries[-1]
        if len(ptts) > 0:
            ptt_list = copy.deepcopy(ptts[-1])
        setup = progress["setup"]
        dataset = progress["dataset"]
    else:
        summaries = []
        all_instructions = []
        ptts = []
        all_command_outputs = []
        current_history = ""
        setup = True
    if os.path.exists(progress_save_path):
        with open(progress_save_path, 'rb') as handle:
            progress = pickle.load(handle)
        dataset = progress["dataset"]

    include_none = not args.dont_include_none
    ask_update_temperature = False
    choice_temperature = 0.01

    used_llm = be_llm if use_be else llm
    def save():
        progress = {
            "summaries": summaries,
            "all_instructions": all_instructions,
            "ptts": ptts,
            "current_history": current_history,
            "all_command_outputs": all_command_outputs,
            "dataset": dataset,
            "setup": setup,
        }
        with open(progress_save_path, 'wb') as handle:
            pickle.dump(progress, handle, protocol=pickle.HIGHEST_PROTOCOL)

    try:
        while True:
            if len(all_instructions) == len(summaries) and len(all_instructions) == len(ptts):
                if not current_history_set:
                    current_history = summarize_summaries(simple_input_parsing_past_summaries_template if use_be else input_parsing_past_summaries_template, used_llm, summary_temperature, summaries, past_summary=current_history,  max_summaries=max_summaries, max_tokens=max_tokens, full=True, dataset=dataset)
                current_history_set = True
                save()
                print("Getting instruction")
                # clean_gnerative_prompt_template if use_be else 
                get_instructions(generative_prompt_template, None, ptt_list, used_llm, generative_temperature, all_instructions, current_history=current_history, force_command=force_command, dataset=dataset)
                save()
            if len(summaries) == len(ptts):
                do_qa(default_qa_template if not use_be else simple_default_qa_template, used_llm, qa_temperature, force_command=False, dataset=dataset)
                summary = get_summary(input_parsing_templates, used_llm, summary_temperature, summaries, all_command_outputs, dataset=dataset)
                save()
            if setup:
                ptt_list = add_ports(ports2ptt, ptt_list=ptt_list)
                print("Updated ptt_list to ", json.dumps(ptt_list, indent=4))
                setup = False
            if not past_history_set:
                # if len(current_history) > 0:
                #     past_history = summarize_summaries(simple_input_parsing_past_summaries_template if use_be else input_parsing_past_summaries_template, used_llm, summary_temperature, summaries, max_summaries=max_summaries, max_tokens=300, dataset=dataset)
                # else:
                past_history = current_history
                past_history_set = True

            print("Current ptt_list: ", ptt_list)
            ptt_list = get_new_ptt_list(simple_reasoning_templates if use_be else reasoning_template, summary, past_history, ptt_list, used_llm, reasoning_temperature, ptts, choice_temperature=choice_temperature, dataset=dataset, include_none=include_none, ask_update_temperature=ask_update_temperature, name_arguments=name_arguments, constrain_generation=args.constrain_generation)
            past_history_set = False
            current_history_set = False
            save()
    except Exception as e:
        print("Exception:", e)
        print(traceback.format_exc())
        save()
args = parse_args()

llm = {
    "url": os.environ["API_URL"],
    "api_key": os.environ["API_KEY"]
}
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}

import json
from PIL import Image
from flask import Flask, jsonify, request, render_template

app = Flask(__name__)
def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


@app.route('/api/summarize', methods=['POST'])
def summarize():
    data = request.get_json()
    terminal_output = data["terminal_output"]
    current_history = data.get("past_history", "")

    summary = input_parser(input_parsing_templates["terminal"], terminal_output, llm, 0.1, max_tokens = 200)
    if current_history == "":
        current_history = summary
    else:
        summaries_combined = "\n"
        summaries_combined += f"Previous Summary: {current_history}\n\n"
        summaries_combined += f"Current Summary: {summary}\n\n"
        current_history = input_parser(simple_input_parsing_past_summaries_template, summaries_combined, llm, 1.0, max_tokens=1024)
    return jsonify({"summary": summary, "current_history": current_history})
@app.route('/api/update_todo', methods=['POST'])
def update_todo():
    data = request.get_json()
    summary = data["summary"]
    past_history = data["past_history"]
    ptt_list = data["todo_list"]

    ptt_list = reasoning_module_tools(simple_reasoning_templates, summary, past_history, ptt_list, llm, reasoning_temperature, [], choice_temperature=choice_temperature, dataset=[], include_none=True, ask_update_temperature=False, name_arguments=False, constrain_generation=args.constrain_generation, ask_confirm=False)
    return jsonify({"todo_list": ptt_list})

@app.route('/api/qna', methods=['POST'])
def qna():
    data = request.get_json()
    question = data["question"]
    return jsonify({"answer": do_qa(default_qa_template, llm, qa_temperature, force_command=False, dataset=[], ask_confirm=False, question=question)})

@app.route('/api/explain_task', methods=['POST'])
def explain_task():
    data = request.get_json()

    ptt_list = data["todo_list"]
    current_history = data.get("current_history", "")

    instructions = get_instructions(generative_prompt_template, None, ptt_list, llm, generative_temperature, [], current_history=current_history, force_command=False, dataset=[], ask_confirm=False) 
    return jsonify({"instruction": instructions})
if __name__ == '__main__':
    app.run(debug=True)
