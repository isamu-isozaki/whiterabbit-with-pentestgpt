{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e33ae58-2330-49d2-96e4-7d906536ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bad156-f443-44ee-bbf7-3f8f7c27d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert task to adding new todo tasks+changing status\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from lmformatenforcer import CharacterLevelParser, JsonSchemaParser\n",
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from prompts import prompts\n",
    "from schema import PTT, update_completion_status_outlines, add_new_items_outlines, update_ptt, find_inprogress, done_added, find_in_progress_task\n",
    "from llama_index.llms.llama_utils import (\n",
    "    messages_to_prompt,\n",
    "    completion_to_prompt,\n",
    ")\n",
    "import copy\n",
    "import gc\n",
    "import outlines\n",
    "from torch import Generator\n",
    "from outlines.samplers import Sampler, multinomial\n",
    "import json\n",
    "from benchmark import load_outlines\n",
    "import json\n",
    "model_paths=[\n",
    "    # \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-33b-v1.Q3_K_S.gguf\",\n",
    "    # \"/mnt/d/projects/gamified-cybersecurity-ai-server/model/whiterabbitneo-33b-v1.Q4_K_S.gguf\",\n",
    "    r\"D:\\personal_projects\\gamified-cybersecurity\\ai-server\\model\\whiterabbitneo-13b.Q3_K_S.gguf\",\n",
    "    r\"D:\\personal_projects\\gamified-cybersecurity\\ai-server\\model\\whiterabbitneo-13b.Q4_K_S.gguf\",\n",
    "    r\"D:\\personal_projects\\gamified-cybersecurity\\ai-server\\model\\whiterabbitneo-13b.Q5_K_S.gguf\",\n",
    "]\n",
    "output_path = \"./benchmark\"\n",
    "\n",
    "instance = {\n",
    "    \"n_gpu_layers\": 15,\n",
    "    \"n_batch\": 1536,\n",
    "    \"top_p\": 1.0,\n",
    "    \"temperature\": 0.5,\n",
    "    \"generate_len\": 1536,\n",
    "    \"top_k\": 50,\n",
    "}\n",
    "import outlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f532adc-344d-48e1-aa49-7e9be762e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 22 key-value pairs and 363 tensors from D:\\personal_projects\\gamified-cybersecurity\\ai-server\\model\\whiterabbitneo-13b.Q4_K_S.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = whiterabbitneo_whiterabbitneo-13b\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 16384\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 14\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32016]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32016]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32016]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_K:  273 tensors\n",
      "llama_model_loader: - type q5_K:    8 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 264/32016 vs 259/32016 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32016\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 16384\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 16384\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.90 GiB (4.56 BPW) \n",
      "llm_load_print_meta: general.name     = whiterabbitneo_whiterabbitneo-13b\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.28 MiB\n",
      "llm_load_tensors: offloading 15 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 15/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  7070.25 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  2552.93 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 1536\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:  CUDA_Host KV buffer size =   750.00 MiB\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   450.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1200.00 MiB, K (f16):  600.00 MiB, V (f16):  600.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =    48.03 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   489.01 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =   510.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 3\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.name': 'whiterabbitneo_whiterabbitneo-13b', 'general.architecture': 'llama', 'llama.context_length': '16384', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '5120', 'llama.block_count': '40', 'llama.feed_forward_length': '13824', 'llama.attention.head_count': '40', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '14', 'llama.attention.head_count_kv': '40', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '1000000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false'}\n"
     ]
    }
   ],
   "source": [
    "llm, sampler = load_outlines(model_paths[1], instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acee435c-29e4-4eb0-ba62-e8080645a07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25d33cd5eb0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = Generator(device=\"cpu\")\n",
    "rng.manual_seed(789005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78ccbfe3-121e-4174-894b-2c98d7b2dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = prompts[\"reasoning_module\"][\"reasoning_session_task_selection_hack_no_schema\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acfe74ab-8f56-46f4-addd-97d2b28bdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"On 142.250.80.46 there is one ssh port open on port 22, a http port on port 80, and a https port on port 443\"\n",
    "ptt = \"\"\"\n",
    "{\"recon\": [\n",
    "        {\"status\": \"inprogress\", \"task_description\": \"Perform a full port scan\"},\n",
    "        {\"status\": \"todo\", \"task_description\": \"Determine the purpose of each open port\"}\n",
    "    ],\n",
    "    \"initial_access\": [],\n",
    "    \"execution\": [],\n",
    "    \"post_exploitation\": []\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b150ab7e-4ecf-446c-9dd5-fc844a4790a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     2 runs   (    0.96 ms per token,  1040.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19801.10 ms /   752 tokens (   26.33 ms per token,    37.98 tokens per second)\n",
      "llama_print_timings:        eval time =     287.35 ms /     1 runs   (  287.35 ms per token,     3.48 tokens per second)\n",
      "llama_print_timings:       total time =   20636.10 ms /   753 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     2 runs   (    0.31 ms per token,  3262.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4973.84 ms /   773 tokens (    6.43 ms per token,   155.41 tokens per second)\n",
      "llama_print_timings:        eval time =     273.78 ms /     1 runs   (  273.78 ms per token,     3.65 tokens per second)\n",
      "llama_print_timings:       total time =    5256.70 ms /   774 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     2 runs   (    0.19 ms per token,  5194.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4797.36 ms /   740 tokens (    6.48 ms per token,   154.25 tokens per second)\n",
      "llama_print_timings:        eval time =     249.72 ms /     1 runs   (  249.72 ms per token,     4.00 tokens per second)\n",
      "llama_print_timings:       total time =    5053.96 ms /   741 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5249.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4742.03 ms /   742 tokens (    6.39 ms per token,   156.47 tokens per second)\n",
      "llama_print_timings:        eval time =     244.79 ms /     1 runs   (  244.79 ms per token,     4.09 tokens per second)\n",
      "llama_print_timings:       total time =    4992.45 ms /   743 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     2 runs   (    0.24 ms per token,  4115.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4714.53 ms /   749 tokens (    6.29 ms per token,   158.87 tokens per second)\n",
      "llama_print_timings:        eval time =     259.04 ms /     1 runs   (  259.04 ms per token,     3.86 tokens per second)\n",
      "llama_print_timings:       total time =    4987.33 ms /   750 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     2 runs   (    0.24 ms per token,  4140.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5087.45 ms /   790 tokens (    6.44 ms per token,   155.28 tokens per second)\n",
      "llama_print_timings:        eval time =     256.27 ms /     1 runs   (  256.27 ms per token,     3.90 tokens per second)\n",
      "llama_print_timings:       total time =    5351.12 ms /   791 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =      15.09 ms /    60 runs   (    0.25 ms per token,  3975.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34464.87 ms /   792 tokens (   43.52 ms per token,    22.98 tokens per second)\n",
      "llama_print_timings:        eval time =   22212.41 ms /    59 runs   (  376.48 ms per token,     2.66 tokens per second)\n",
      "llama_print_timings:       total time =   57455.15 ms /   851 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5601.95 ms /   814 tokens (    6.88 ms per token,   145.31 tokens per second)\n",
      "llama_print_timings:        eval time =     415.89 ms /     1 runs   (  415.89 ms per token,     2.40 tokens per second)\n",
      "llama_print_timings:       total time =    6027.17 ms /   815 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     2 runs   (    0.27 ms per token,  3752.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5542.01 ms /   815 tokens (    6.80 ms per token,   147.06 tokens per second)\n",
      "llama_print_timings:        eval time =     264.30 ms /     1 runs   (  264.30 ms per token,     3.78 tokens per second)\n",
      "llama_print_timings:       total time =    5815.13 ms /   816 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     2 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5574.85 ms /   823 tokens (    6.77 ms per token,   147.63 tokens per second)\n",
      "llama_print_timings:        eval time =     302.45 ms /     1 runs   (  302.45 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =    5885.24 ms /   824 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     2 runs   (    0.29 ms per token,  3424.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6819.82 ms /   825 tokens (    8.27 ms per token,   120.97 tokens per second)\n",
      "llama_print_timings:        eval time =     425.88 ms /     1 runs   (  425.88 ms per token,     2.35 tokens per second)\n",
      "llama_print_timings:       total time =    7256.34 ms /   826 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =      16.29 ms /    64 runs   (    0.25 ms per token,  3927.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6838.12 ms /   827 tokens (    8.27 ms per token,   120.94 tokens per second)\n",
      "llama_print_timings:        eval time =   24104.86 ms /    63 runs   (  382.62 ms per token,     2.61 tokens per second)\n",
      "llama_print_timings:       total time =   31259.62 ms /   890 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     2 runs   (    0.25 ms per token,  4000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6660.19 ms /   854 tokens (    7.80 ms per token,   128.22 tokens per second)\n",
      "llama_print_timings:        eval time =     362.25 ms /     1 runs   (  362.25 ms per token,     2.76 tokens per second)\n",
      "llama_print_timings:       total time =    7032.72 ms /   855 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     2 runs   (    0.38 ms per token,  2621.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6572.65 ms /   855 tokens (    7.69 ms per token,   130.08 tokens per second)\n",
      "llama_print_timings:        eval time =     587.37 ms /     1 runs   (  587.37 ms per token,     1.70 tokens per second)\n",
      "llama_print_timings:       total time =    7176.03 ms /   856 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     2 runs   (    0.25 ms per token,  4008.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6205.91 ms /   861 tokens (    7.21 ms per token,   138.74 tokens per second)\n",
      "llama_print_timings:        eval time =     277.65 ms /     1 runs   (  277.65 ms per token,     3.60 tokens per second)\n",
      "llama_print_timings:       total time =    6495.74 ms /   862 tokens\n",
      "\n",
      "llama_print_timings:        load time =  112949.52 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6552.56 ms /   872 tokens (    7.51 ms per token,   133.08 tokens per second)\n",
      "llama_print_timings:        eval time =     509.17 ms /     1 runs   (  509.17 ms per token,     1.96 tokens per second)\n",
      "llama_print_timings:       total time =    7070.72 ms /   873 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  {\n",
      "   \"recon\": [\n",
      "       {\"status\":\"done\", \"task_description\": \"Perform a full port scan\"},{\"status\":\"done\", \"task_description\": \"Determine the purpose of each open port\"},\n",
      "      {\"status\": \"inprogress\", \"task_description\": \"Use Nmap script for service enumeration\"}],\n",
      "   \"initial_access\": [\n",
      "     \t  {\"status\": \"todo\", \"task_description\": \"Identify credentials if any (e.g., SSH keys)\"}],\n",
      "  \"execution\": [\n",
      "     ],\"post_exploitation\": [\n",
      "    ]}\n",
      "Generated\n",
      "{'recon': [{'status': 'done', 'task_description': 'Perform a full port scan'}, {'status': 'done', 'task_description': 'Determine the purpose of each open port'}, {'status': 'inprogress', 'task_description': 'Use Nmap script for service enumeration'}], 'initial_access': [{'status': 'todo', 'task_description': 'Identify credentials if any (e.g., SSH keys)'}], 'execution': [], 'post_exploitation': []}\n"
     ]
    }
   ],
   "source": [
    "output = update_ptt(template, prompt, ptt, llm, sampler, max_spaces=2, force_add_task={\"recon\": True, \"initial_access\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2f9640f-59b6-469d-8caa-585867eee8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recon': [{'status': 'done', 'task_description': 'Perform a full port scan'},\n",
       "  {'status': 'done',\n",
       "   'task_description': 'Determine the purpose of each open port'},\n",
       "  {'status': 'inprogress',\n",
       "   'task_description': 'Use Nmap script for service enumeration'}],\n",
       " 'initial_access': [{'status': 'todo',\n",
       "   'task_description': 'Identify credentials if any (e.g., SSH keys)'}],\n",
       " 'execution': [],\n",
       " 'post_exploitation': []}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de1515-2e14-4565-96a6-cc713c174451",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(final_output.replace(\"'\", '\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a296e4e3-057c-47cc-b916-4a1ff24ee7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d78d1dd4-be8a-4032-b1c7-bbe07bbea015",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptt = {\n",
    " 'recon': [],\n",
    " 'initial_access': [],\n",
    " 'execution': [],\n",
    " 'post_exploitation': []\n",
    "}\n",
    "ptt = str(ptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19c06f50-ff44-4056-aea5-390719dfccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f18cc9-7354-4a28-ad1c-66fd411df719",
   "metadata": {},
   "source": [
    "# Testing PTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a72f86c-42f8-449d-ad6f-6bb0afc6799d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please describe the penetration testing task in one line, including the target IP, task type, etc.\n",
      ">  I want to hack into 10.10.11.242 and retrieve a file with a hash\n"
     ]
    }
   ],
   "source": [
    "#Initial prompt to user\n",
    "initial_prompt = \"Please describe the penetration testing task in one line, including the target IP, task type, etc.\\n> \"\n",
    "user_answer = input(initial_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b14a737a-4810-479e-b44c-126abbd09557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to hack into 10.10.11.242 and retrieve a file with a hash'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "642202f2-609a-4d67-bae8-4d68e6f9a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_chat_history.append(user_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8860aebe-29ff-4efc-aeb9-fae430cdf601",
   "metadata": {},
   "source": [
    "# Reasoning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41897e10-2c4b-4773-98e8-d1181971a6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5586.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4720.98 ms /   659 tokens (    7.16 ms per token,   139.59 tokens per second)\n",
      "llama_print_timings:        eval time =     242.21 ms /     1 runs   (  242.21 ms per token,     4.13 tokens per second)\n",
      "llama_print_timings:       total time =    4969.81 ms /   660 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     2 runs   (    0.33 ms per token,  3062.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4440.96 ms /   661 tokens (    6.72 ms per token,   148.84 tokens per second)\n",
      "llama_print_timings:        eval time =     289.68 ms /     1 runs   (  289.68 ms per token,     3.45 tokens per second)\n",
      "llama_print_timings:       total time =    4740.85 ms /   662 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     2 runs   (    0.36 ms per token,  2754.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4604.14 ms /   668 tokens (    6.89 ms per token,   145.09 tokens per second)\n",
      "llama_print_timings:        eval time =     617.98 ms /     1 runs   (  617.98 ms per token,     1.62 tokens per second)\n",
      "llama_print_timings:       total time =    5247.98 ms /   669 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.20 ms per token,  4889.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5786.38 ms /   670 tokens (    8.64 ms per token,   115.79 tokens per second)\n",
      "llama_print_timings:        eval time =     317.98 ms /     1 runs   (  317.98 ms per token,     3.14 tokens per second)\n",
      "llama_print_timings:       total time =    6112.32 ms /   671 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =      23.46 ms /    57 runs   (    0.41 ms per token,  2429.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6916.62 ms /   672 tokens (   10.29 ms per token,    97.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19825.26 ms /    56 runs   (  354.02 ms per token,     2.82 tokens per second)\n",
      "llama_print_timings:       total time =   27012.04 ms /   728 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5263.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5317.69 ms /   691 tokens (    7.70 ms per token,   129.94 tokens per second)\n",
      "llama_print_timings:        eval time =     278.20 ms /     1 runs   (  278.20 ms per token,     3.59 tokens per second)\n",
      "llama_print_timings:       total time =    5602.28 ms /   692 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5089.70 ms /   692 tokens (    7.36 ms per token,   135.96 tokens per second)\n",
      "llama_print_timings:        eval time =     299.92 ms /     1 runs   (  299.92 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =    5398.47 ms /   693 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     2 runs   (    0.25 ms per token,  3968.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5005.02 ms /   700 tokens (    7.15 ms per token,   139.86 tokens per second)\n",
      "llama_print_timings:        eval time =     326.93 ms /     1 runs   (  326.93 ms per token,     3.06 tokens per second)\n",
      "llama_print_timings:       total time =    5339.65 ms /   701 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5682.04 ms /   707 tokens (    8.04 ms per token,   124.43 tokens per second)\n",
      "llama_print_timings:        eval time =     329.77 ms /     1 runs   (  329.77 ms per token,     3.03 tokens per second)\n",
      "llama_print_timings:       total time =    6019.78 ms /   708 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5132.67 ms /   718 tokens (    7.15 ms per token,   139.89 tokens per second)\n",
      "llama_print_timings:        eval time =     418.90 ms /     1 runs   (  418.90 ms per token,     2.39 tokens per second)\n",
      "llama_print_timings:       total time =    5559.53 ms /   719 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated\n",
      "{'recon': [{'status': 'todo', 'task_description': 'Perform DNS enumeration'}], 'initial_access': [], 'execution': [], 'post_exploitation': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     3 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4906.73 ms /   688 tokens (    7.13 ms per token,   140.22 tokens per second)\n",
      "llama_print_timings:        eval time =     571.08 ms /     2 runs   (  285.54 ms per token,     3.50 tokens per second)\n",
      "llama_print_timings:       total time =    5489.43 ms /   690 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4246.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5447.94 ms /   679 tokens (    8.02 ms per token,   124.63 tokens per second)\n",
      "llama_print_timings:        eval time =     312.80 ms /     1 runs   (  312.80 ms per token,     3.20 tokens per second)\n",
      "llama_print_timings:       total time =    5770.70 ms /   680 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.21 ms per token,  4662.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5358.80 ms /   681 tokens (    7.87 ms per token,   127.08 tokens per second)\n",
      "llama_print_timings:        eval time =     309.50 ms /     1 runs   (  309.50 ms per token,     3.23 tokens per second)\n",
      "llama_print_timings:       total time =    5676.57 ms /   682 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     2 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4592.12 ms /   688 tokens (    6.67 ms per token,   149.82 tokens per second)\n",
      "llama_print_timings:        eval time =     304.02 ms /     1 runs   (  304.02 ms per token,     3.29 tokens per second)\n",
      "llama_print_timings:       total time =    4903.76 ms /   689 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.20 ms per token,  4889.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5847.89 ms /   708 tokens (    8.26 ms per token,   121.07 tokens per second)\n",
      "llama_print_timings:        eval time =     318.30 ms /     1 runs   (  318.30 ms per token,     3.14 tokens per second)\n",
      "llama_print_timings:       total time =    6174.14 ms /   709 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =      16.87 ms /    71 runs   (    0.24 ms per token,  4208.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6035.97 ms /   710 tokens (    8.50 ms per token,   117.63 tokens per second)\n",
      "llama_print_timings:        eval time =   25256.22 ms /    70 runs   (  360.80 ms per token,     2.77 tokens per second)\n",
      "llama_print_timings:       total time =   31610.79 ms /   780 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.23 ms per token,  4273.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5081.70 ms /   743 tokens (    6.84 ms per token,   146.21 tokens per second)\n",
      "llama_print_timings:        eval time =     317.22 ms /     1 runs   (  317.22 ms per token,     3.15 tokens per second)\n",
      "llama_print_timings:       total time =    5407.26 ms /   744 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4228.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5298.01 ms /   744 tokens (    7.12 ms per token,   140.43 tokens per second)\n",
      "llama_print_timings:        eval time =     423.69 ms /     1 runs   (  423.69 ms per token,     2.36 tokens per second)\n",
      "llama_print_timings:       total time =    5730.77 ms /   745 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     2 runs   (    0.25 ms per token,  4008.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5669.18 ms /   752 tokens (    7.54 ms per token,   132.65 tokens per second)\n",
      "llama_print_timings:        eval time =     281.86 ms /     1 runs   (  281.86 ms per token,     3.55 tokens per second)\n",
      "llama_print_timings:       total time =    5958.12 ms /   753 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.52 ms /     2 runs   (    0.26 ms per token,  3868.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5408.03 ms /   759 tokens (    7.13 ms per token,   140.35 tokens per second)\n",
      "llama_print_timings:        eval time =     380.89 ms /     1 runs   (  380.89 ms per token,     2.63 tokens per second)\n",
      "llama_print_timings:       total time =    5798.98 ms /   760 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4219.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5940.36 ms /   770 tokens (    7.71 ms per token,   129.62 tokens per second)\n",
      "llama_print_timings:        eval time =     282.24 ms /     1 runs   (  282.24 ms per token,     3.54 tokens per second)\n",
      "llama_print_timings:       total time =    6232.41 ms /   771 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated\n",
      "{'recon': [{'task_description': 'Perform DNS enumeration', 'status': 'todo'}, {'status': 'inprogress', 'task_description': 'Identify subdomains of 10.10.11.242'}], 'initial_access': [], 'execution': [], 'post_exploitation': []}\n"
     ]
    }
   ],
   "source": [
    "reasoning_template = prompts[\"reasoning_module\"][\"reasoning_session_task_selection_hack_no_schema\"]\n",
    "initial_ptt = update_ptt(reasoning_template, user_answer, ptt, force_add_task={\"recon\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d040fab-aee5-4e24-b87a-a32917d1a706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recon': [{'task_description': 'Perform DNS enumeration', 'status': 'todo'},\n",
       "  {'status': 'inprogress',\n",
       "   'task_description': 'Identify subdomains of 10.10.11.242'}],\n",
       " 'initial_access': [],\n",
       " 'execution': [],\n",
       " 'post_exploitation': []}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_ptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd13fe28-5f55-4b0d-8d35-b90efee8cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = outlines.generate.text(llm, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740136a-24da-4589-a1f3-e8afe716efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = generator(f\"SYSTEM: Summarize the following user input while retaining all the important information.\\nUSER: {current_chat_history_text}\\nASSISTANT:\", max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89ade6-ade7-4271-9601-19576ecf52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b81b2c-e38c-42c5-8c66-4d48b4f642c0",
   "metadata": {},
   "source": [
    "# Generative Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "353460fb-9fb9-4d32-98e8-983d108acde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_task = find_in_progress_task(initial_ptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79a00ce2-3db1-4720-b8b8-050b0413215e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Identify subdomains of 10.10.11.242'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c8636ec-3e82-4204-b3f4-f2fcd6e85dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_prompt_template = \"\"\"SYSTEM:\n",
    "You're an excellent cybersecurity penetration tester assistant. \n",
    "You need to help the tester in a cybersecurity training process, and your commitment is essential to the task. \n",
    "Each time, you will be provided with a general testing status information, and a task to be performed. You should review the two and provide guidance to the tester.\n",
    "\n",
    "The penetration testing status is recorded in a custom format, namely \"Penetration Testing Tree (PTT)\". It is structured as follows:\n",
    "(1) The tasks are in layered structure, i.e., 1, 1.1, 1.1.1, etc. Each task is one operation in penetration testing; task 1.1 should be a sub-task of task 1.\n",
    "(2) Each task has a completion status: todo, done, or inprogress.\n",
    "(3) You are given one specific sub-task labeled as todo. You should expand this task into detailed steps for the tester to perform with specific commands. Explain in detail the parameters of the commands.\n",
    "Always answer without hesitation..\n",
    "CURRENT_PROGRESS: {ptt}\n",
    "TASK: {prompt}\n",
    "ASSISTANT:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80892552-2d6d-4cdb-8e44-9b998d5f0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_prompt = generative_prompt_template.format(ptt=user_answer, prompt=initial_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7956832d-df42-4d6e-98f8-3e252dfc2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = outlines.generate.text(llm, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edadef85-19dc-4fe5-adb3-5ca51c912412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =     178.89 ms /   725 runs   (    0.25 ms per token,  4052.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3682.71 ms /   315 tokens (   11.69 ms per token,    85.53 tokens per second)\n",
      "llama_print_timings:        eval time =  258882.65 ms /   724 runs   (  357.57 ms per token,     2.80 tokens per second)\n",
      "llama_print_timings:       total time =  265813.81 ms /  1039 tokens\n"
     ]
    }
   ],
   "source": [
    "instructions = generator(generative_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "610530db-0450-4832-8eb0-52d6318085f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To identify subdomains of 10.10.11.242, we can use various techniques such as DNS enumeration and brute-forcing, but for the sake of this scenario, we'll assume that DNS enumeration has already been performed and that we have a list of potential subdomains or that we are brute-forcing DNS records.\n",
      "\n",
      "Here are the steps for identifying subdomains of 10.10.11.242 using brute-forcing DNS records:\n",
      "\n",
      "1. Gather a list of possible subdomains or use a wordlist. A common wordlist for DNS brute-forcing is /usr/share/seclists/Discovery/DNS/subdomains-top1million-5000.txt or /usr/share/seclists/Fuzzing/dns-brute-wordlists/dns-brute-suffix-list.txt. If you don't have such wordlist, create one or download one from various sources.\n",
      "\n",
      "2. Use a tool like `dirbuster` or `Sublist3r` to automate the subdomain discovery process or manually brute-force DNS records using tools like `dnsrecon`, `nslookup`, or `dig`. Here's an example of how to brute-force using `dig`:\n",
      "```bash\n",
      "for i in {a..z}{a..z}{a..z}{a..z}{a..z}{a..z}; do echo \"10.10.11.$i.\"; done | dig @10.10.11.255 -f - +short | grep \".\" | sort -u > subdomains.txt\n",
      "```\n",
      "This command assumes that the target network uses a non-privileged range (like 10.x.x.x) where DNS resolution is likely to be successful. The command generates all possible subdomains for the range (a..z) and appends them to `subdomains.txt` which contains the resolved subdomains after running `dig` against each one.\n",
      "\n",
      "3. Once you have a list of resolved subdomains, visit each one and look for open ports or services running on them using `nmap` or similar tools. For example:\n",
      "```bash\n",
      "for domain in $(cat subdomains.txt); do nmap -p- $domain; done\n",
      "```\n",
      "This command will scan all TCP/UDP ports for each discovered subdomain using `nmap`.\n",
      "\n",
      "4. Analyze the results from `nmap` for any open ports or services that could be vulnerable. Look for services that are known to have known vulnerabilities or misconfigurations that could be exploited.\n",
      "\n",
      "5. If necessary, proceed to exploit the identified vulnerabilities using tools like Metasploit or manually crafting exploits based on the vulnerabilities discovered.\n",
      "\n",
      "6. After exploiting the system, if authorized by the owner of the target, document all activities and data obtained during the penetration test for review and reporting purposes.\n",
      "\n",
      "Please note that this is a simplified example. Real-world scenarios would require more careful planning, legal authorization, and respect for privacy. Unauthorized penetration testing on networks or systems is illegal and unethical.\n"
     ]
    }
   ],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958aa38b-c19c-4d47-ba36-6a078d7f056d",
   "metadata": {},
   "source": [
    "# Input Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e6bfda0-1b1c-41f1-99e2-ea53bbbb37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_output = \"\"\"sudo nmap -sV -O 10.10.11.242\n",
    "\n",
    "Starting Nmap 7.60 ( https://nmap.org ) at 2024-03-01 00:29 EST\n",
    "Nmap scan report for 10.10.11.242\n",
    "Host is up (0.017s latency).\n",
    "Not shown: 998 closed ports\n",
    "PORT   STATE SERVICE VERSION\n",
    "22/tcp open  ssh     OpenSSH 8.2p1 Ubuntu 4ubuntu0.9 (Ubuntu Linux; protocol 2.0)\n",
    "80/tcp open  http    nginx 1.18.0 (Ubuntu)\n",
    "No exact OS matches for host (If you know what OS is running on it, see https://nmap.org/submit/ ).\n",
    "TCP/IP fingerprint:\n",
    "OS:SCAN(V=7.60%E=4%D=3/1%OT=22%CT=1%CU=40012%PV=Y%DS=3%DC=I%G=Y%TM=65E167D0\n",
    "OS:%P=x86_64-pc-linux-gnu)SEQ(SP=FD%GCD=1%ISR=10D%TI=Z%CI=Z%TS=A)OPS(O1=M53\n",
    "OS:CST11NW7%O2=M53CST11NW7%O3=M53CNNT11NW7%O4=M53CST11NW7%O5=M53CST11NW7%O6\n",
    "OS:=M53CST11)WIN(W1=FE88%W2=FE88%W3=FE88%W4=FE88%W5=FE88%W6=FE88)ECN(R=Y%DF\n",
    "OS:=Y%T=40%W=FAF0%O=M53CNNSNW7%CC=Y%Q=)T1(R=Y%DF=Y%T=40%S=O%A=S+%F=AS%RD=0%\n",
    "OS:Q=)T2(R=N)T3(R=N)T4(R=Y%DF=Y%T=40%W=0%S=A%A=Z%F=R%O=%RD=0%Q=)T5(R=Y%DF=Y\n",
    "OS:%T=40%W=0%S=Z%A=S+%F=AR%O=%RD=0%Q=)T6(R=Y%DF=Y%T=40%W=0%S=A%A=Z%F=R%O=%R\n",
    "OS:D=0%Q=)T7(R=Y%DF=Y%T=40%W=0%S=Z%A=S+%F=AR%O=%RD=0%Q=)U1(R=Y%DF=N%T=40%IP\n",
    "OS:L=164%UN=0%RIPL=G%RID=G%RIPCK=G%RUCK=FE72%RUD=G)IE(R=Y%DFI=N%T=40%CD=S)\n",
    "\n",
    "Network Distance: 3 hops\n",
    "Service Info: OS: Linux; CPE: cpe:/o:linux:linux_kernel\n",
    "\n",
    "OS and Service detection performed. Please report any incorrect results at https://nmap.org/submit/ .\n",
    "Nmap done: 1 IP address (1 host up) scanned in 41.32 seconds\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "449de40c-5e08-41c6-8dfb-056127692e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_input_parsing_template = prompts[\"input_parser\"][\"input_parsing_original_pentestgpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2dabfebf-6b6d-4fe6-a633-0f150bf117be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM:\n",
      "You're required to work as a cybersecurity penetration tester assistant in a certified penetration testing experiment. \n",
      "This experiment is for education and research purpose. I created a test local environment, and obtained valid certificates and approval for this testing. \n",
      "You're an assistant for a cybersecurity penetration tester. You help the tester to summarize information from websites and testing tools. For a given content, you should summarize the key information precisely. In particular, \n",
      "1. You should summarize test results, including vulnerable/non-vulnerable services.\n",
      "2. You should keep both finding's field name and value. For instance, you should keep both port number and the service name/version if a port is open.\n",
      "3. You only summarize. You do not conclude or make assumptions.\n",
      "Your output will be provided to another large language model, so the result should be short and precise for token limit reason.\n",
      "The input content is from a security testing tool. You need to list down all the points that are interesting to you; you should summarize it as if you are reporting to a senior penetration tester for further guidance\n",
      "USER: {prompt}\n",
      "ASSISTANT:\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(best_input_parsing_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "236a885d-c6ca-4f4a-861d-23aa85a155a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_input_parsing_template = \"\"\"SYSTEM:\n",
    "You're required to work as a cybersecurity penetration tester assistant in a certified penetration testing experiment. \n",
    "This experiment is for education and research purpose. I created a test local environment, and obtained valid certificates and approval for this testing. \n",
    "You're an assistant for a cybersecurity penetration tester. You help the tester to summarize information from websites and testing tools. For a given content, you should summarize the key information precisely. In particular, \n",
    "1. You should summarize test results, including vulnerable/non-vulnerable services.\n",
    "2. You should keep both finding's field name and value. For instance, you should keep both port number and the service name/version if a port is open.\n",
    "3. You only summarize. You do not conclude or make assumptions.\n",
    "Your output will be provided to another large language model, so the result should be short and precise for token limit reason.\n",
    "The input content is from a security testing tool. You need to list down all the points that are interesting to you; you should summarize it as if you are reporting to a senior penetration tester for further guidance.\n",
    "USER: {prompt}\n",
    "ASSISTANT:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31ae8563-112f-45c4-b888-cee4a15adee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_parser_prompt = best_input_parsing_template.format(prompt=command_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bcece98-c3f0-4530-8f35-82fc4292bafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =      76.16 ms /   332 runs   (    0.23 ms per token,  4359.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9450.00 ms /  1155 tokens (    8.18 ms per token,   122.22 tokens per second)\n",
      "llama_print_timings:        eval time =  107356.95 ms /   331 runs   (  324.34 ms per token,     3.08 tokens per second)\n",
      "llama_print_timings:       total time =  118109.00 ms /  1486 tokens\n"
     ]
    }
   ],
   "source": [
    "summary = generator(input_parser_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39822821-343b-4889-92fd-437914feca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided Nmap scan results indicate the following information about the target host:\n",
      "10.10.11.242\n",
      "- The host is up with a latency of 0.017 seconds.\n",
      "- There are several closed ports that are not shown due to the `-O` flag being used.\n",
      "- Port 22 (SSH) is open with an OpenSSH server version of `OpenSSH 8.2p1 Ubuntu 4ubuntu0.9`.\n",
      "- Port 80 (HTTP) is open with an nginx server version `nginx 1.18.0`.\n",
      "- The OS fingerprint indicates that the system is running Ubuntu Linux (x86_64 architecture).\n",
      "- The Nmap scan also found that the target has not been detected with an exact OS match.\n",
      "- The service information is provided by Nmap's Service/Version detection feature (NSE).\n",
      "- The distance between the scanner and the target host is reported as 3 hops.\n",
      "\n",
      "Please note that the `-O` flag in Nmap is used to enable OS detection, which can sometimes be misleading due to the lack of accuracy of such detection methods. However, it can still provide valuable information about the operating system version or distribution, which can be helpful when preparing the assessment plan or when working with the target system.\n",
      "\n",
      "For further analysis or vulnerability assessment, it may be necessary to use additional tools like Metasploit or Nessus to perform more in-depth scanning and vulnerability assessment.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03c6dd29-55c3-424e-8e1d-a84a26e211a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_chat_history.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc3ea83-05bf-4672-87cc-81d3df8101a0",
   "metadata": {},
   "source": [
    "# Reasoning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7be3177-ab55-44b9-8702-7ebf90a9267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptt = str(initial_ptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f0628bf-2546-4d54-8f14-6327ae6dae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'recon': [{'task_description': 'Perform DNS enumeration', 'status': 'todo'}, {'status': 'inprogress', 'task_description': 'Identify subdomains of 10.10.11.242'}], 'initial_access': [], 'execution': [], 'post_exploitation': []}\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6154bfd-62e5-4487-a48a-54320e6b4291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5221.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6666.58 ms /  1039 tokens (    6.42 ms per token,   155.85 tokens per second)\n",
      "llama_print_timings:        eval time =     272.49 ms /     1 runs   (  272.49 ms per token,     3.67 tokens per second)\n",
      "llama_print_timings:       total time =    6947.06 ms /  1040 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6633.85 ms /  1045 tokens (    6.35 ms per token,   157.53 tokens per second)\n",
      "llama_print_timings:        eval time =     261.29 ms /     1 runs   (  261.29 ms per token,     3.83 tokens per second)\n",
      "llama_print_timings:       total time =    6902.63 ms /  1046 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     2 runs   (    0.25 ms per token,  4008.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6611.62 ms /  1018 tokens (    6.49 ms per token,   153.97 tokens per second)\n",
      "llama_print_timings:        eval time =     296.51 ms /     1 runs   (  296.51 ms per token,     3.37 tokens per second)\n",
      "llama_print_timings:       total time =    6916.97 ms /  1019 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5291.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6940.15 ms /  1020 tokens (    6.80 ms per token,   146.97 tokens per second)\n",
      "llama_print_timings:        eval time =     318.81 ms /     1 runs   (  318.81 ms per token,     3.14 tokens per second)\n",
      "llama_print_timings:       total time =    7266.36 ms /  1021 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  5012.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7172.05 ms /  1027 tokens (    6.98 ms per token,   143.19 tokens per second)\n",
      "llama_print_timings:        eval time =     257.88 ms /     1 runs   (  257.88 ms per token,     3.88 tokens per second)\n",
      "llama_print_timings:       total time =    7436.93 ms /  1028 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     2 runs   (    0.24 ms per token,  4175.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7791.26 ms /  1077 tokens (    7.23 ms per token,   138.23 tokens per second)\n",
      "llama_print_timings:        eval time =     285.32 ms /     1 runs   (  285.32 ms per token,     3.50 tokens per second)\n",
      "llama_print_timings:       total time =    8084.04 ms /  1078 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =      16.88 ms /    72 runs   (    0.23 ms per token,  4265.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8538.07 ms /  1079 tokens (    7.91 ms per token,   126.38 tokens per second)\n",
      "llama_print_timings:        eval time =   21676.25 ms /    71 runs   (  305.30 ms per token,     3.28 tokens per second)\n",
      "llama_print_timings:       total time =   30529.38 ms /  1150 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     2 runs   (    0.27 ms per token,  3717.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7507.05 ms /  1113 tokens (    6.74 ms per token,   148.26 tokens per second)\n",
      "llama_print_timings:        eval time =     283.73 ms /     1 runs   (  283.73 ms per token,     3.52 tokens per second)\n",
      "llama_print_timings:       total time =    7798.67 ms /  1114 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7616.60 ms /  1114 tokens (    6.84 ms per token,   146.26 tokens per second)\n",
      "llama_print_timings:        eval time =     275.84 ms /     1 runs   (  275.84 ms per token,     3.63 tokens per second)\n",
      "llama_print_timings:       total time =    7899.12 ms /  1115 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4761.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7565.85 ms /  1122 tokens (    6.74 ms per token,   148.30 tokens per second)\n",
      "llama_print_timings:        eval time =     265.49 ms /     1 runs   (  265.49 ms per token,     3.77 tokens per second)\n",
      "llama_print_timings:       total time =    7840.75 ms /  1123 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7700.39 ms /  1124 tokens (    6.85 ms per token,   145.97 tokens per second)\n",
      "llama_print_timings:        eval time =     274.69 ms /     1 runs   (  274.69 ms per token,     3.64 tokens per second)\n",
      "llama_print_timings:       total time =    7983.46 ms /  1125 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    60 runs   (    0.23 ms per token,  4332.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7951.49 ms /  1126 tokens (    7.06 ms per token,   141.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19561.64 ms /    59 runs   (  331.55 ms per token,     3.02 tokens per second)\n",
      "llama_print_timings:       total time =   27776.06 ms /  1185 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.22 ms per token,  4618.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7801.15 ms /  1148 tokens (    6.80 ms per token,   147.16 tokens per second)\n",
      "llama_print_timings:        eval time =     291.42 ms /     1 runs   (  291.42 ms per token,     3.43 tokens per second)\n",
      "llama_print_timings:       total time =    8100.25 ms /  1149 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4773.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7705.62 ms /  1149 tokens (    6.71 ms per token,   149.11 tokens per second)\n",
      "llama_print_timings:        eval time =     279.85 ms /     1 runs   (  279.85 ms per token,     3.57 tokens per second)\n",
      "llama_print_timings:       total time =    7993.11 ms /  1150 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.22 ms per token,  4608.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8014.45 ms /  1154 tokens (    6.94 ms per token,   143.99 tokens per second)\n",
      "llama_print_timings:        eval time =     267.06 ms /     1 runs   (  267.06 ms per token,     3.74 tokens per second)\n",
      "llama_print_timings:       total time =    8292.44 ms /  1155 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8618.34 ms /  1165 tokens (    7.40 ms per token,   135.18 tokens per second)\n",
      "llama_print_timings:        eval time =     411.76 ms /     1 runs   (  411.76 ms per token,     2.43 tokens per second)\n",
      "llama_print_timings:       total time =    9041.36 ms /  1166 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated\n",
      "{'recon': [{'task_description': 'Perform DNS enumeration', 'status': 'done'}, {'task_description': 'Identify subdomains of 10.10.11.242', 'status': 'done'}, {'status': 'todo', 'task_description': 'Reconnaissance of subdomain 10.10.11.242'}], 'initial_access': [{'status': 'todo', 'task_description': 'Assess credentials obtained from DNS enumeration'}], 'execution': [], 'post_exploitation': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.20 ms per token,  4914.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8191.69 ms /  1132 tokens (    7.24 ms per token,   138.19 tokens per second)\n",
      "llama_print_timings:        eval time =     271.03 ms /     1 runs   (  271.03 ms per token,     3.69 tokens per second)\n",
      "llama_print_timings:       total time =    8477.52 ms /  1133 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  5063.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8128.24 ms /  1172 tokens (    6.94 ms per token,   144.19 tokens per second)\n",
      "llama_print_timings:        eval time =     261.62 ms /     1 runs   (  261.62 ms per token,     3.82 tokens per second)\n",
      "llama_print_timings:       total time =    8397.79 ms /  1173 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     2 runs   (    0.27 ms per token,  3669.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7466.56 ms /  1073 tokens (    6.96 ms per token,   143.71 tokens per second)\n",
      "llama_print_timings:        eval time =     289.98 ms /     1 runs   (  289.98 ms per token,     3.45 tokens per second)\n",
      "llama_print_timings:       total time =    7765.10 ms /  1074 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.22 ms per token,  4618.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7886.06 ms /  1075 tokens (    7.34 ms per token,   136.32 tokens per second)\n",
      "llama_print_timings:        eval time =     300.26 ms /     1 runs   (  300.26 ms per token,     3.33 tokens per second)\n",
      "llama_print_timings:       total time =    8195.20 ms /  1076 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4255.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8223.86 ms /  1082 tokens (    7.60 ms per token,   131.57 tokens per second)\n",
      "llama_print_timings:        eval time =     288.16 ms /     1 runs   (  288.16 ms per token,     3.47 tokens per second)\n",
      "llama_print_timings:       total time =    8520.39 ms /  1083 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4338.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8510.75 ms /  1164 tokens (    7.31 ms per token,   136.77 tokens per second)\n",
      "llama_print_timings:        eval time =     301.91 ms /     1 runs   (  301.91 ms per token,     3.31 tokens per second)\n",
      "llama_print_timings:       total time =    8821.54 ms /  1165 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =      13.94 ms /    60 runs   (    0.23 ms per token,  4305.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8501.65 ms /  1166 tokens (    7.29 ms per token,   137.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18969.54 ms /    59 runs   (  321.52 ms per token,     3.11 tokens per second)\n",
      "llama_print_timings:       total time =   27731.00 ms /  1225 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4319.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8241.87 ms /  1188 tokens (    6.94 ms per token,   144.14 tokens per second)\n",
      "llama_print_timings:        eval time =     283.62 ms /     1 runs   (  283.62 ms per token,     3.53 tokens per second)\n",
      "llama_print_timings:       total time =    8533.33 ms /  1189 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.22 ms per token,  4474.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8700.88 ms /  1189 tokens (    7.32 ms per token,   136.65 tokens per second)\n",
      "llama_print_timings:        eval time =     329.24 ms /     1 runs   (  329.24 ms per token,     3.04 tokens per second)\n",
      "llama_print_timings:       total time =    9038.59 ms /  1190 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.23 ms per token,  4415.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8653.17 ms /  1197 tokens (    7.23 ms per token,   138.33 tokens per second)\n",
      "llama_print_timings:        eval time =     287.03 ms /     1 runs   (  287.03 ms per token,     3.48 tokens per second)\n",
      "llama_print_timings:       total time =    8948.98 ms /  1198 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     2 runs   (    0.30 ms per token,  3344.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8791.56 ms /  1219 tokens (    7.21 ms per token,   138.66 tokens per second)\n",
      "llama_print_timings:        eval time =     313.20 ms /     1 runs   (  313.20 ms per token,     3.19 tokens per second)\n",
      "llama_print_timings:       total time =    9113.75 ms /  1220 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =      14.84 ms /    68 runs   (    0.22 ms per token,  4582.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8620.72 ms /  1221 tokens (    7.06 ms per token,   141.64 tokens per second)\n",
      "llama_print_timings:        eval time =   22515.80 ms /    67 runs   (  336.06 ms per token,     2.98 tokens per second)\n",
      "llama_print_timings:       total time =   31417.35 ms /  1288 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.37 ms /     2 runs   (    0.18 ms per token,  5434.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9445.74 ms /  1251 tokens (    7.55 ms per token,   132.44 tokens per second)\n",
      "llama_print_timings:        eval time =     264.53 ms /     1 runs   (  264.53 ms per token,     3.78 tokens per second)\n",
      "llama_print_timings:       total time =    9718.46 ms /  1252 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.21 ms per token,  4651.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8730.09 ms /  1252 tokens (    6.97 ms per token,   143.41 tokens per second)\n",
      "llama_print_timings:        eval time =     262.49 ms /     1 runs   (  262.49 ms per token,     3.81 tokens per second)\n",
      "llama_print_timings:       total time =    9000.59 ms /  1253 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.21 ms per token,  4662.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9075.05 ms /  1257 tokens (    7.22 ms per token,   138.51 tokens per second)\n",
      "llama_print_timings:        eval time =     292.43 ms /     1 runs   (  292.43 ms per token,     3.42 tokens per second)\n",
      "llama_print_timings:       total time =    9376.18 ms /  1258 tokens\n",
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     2 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9239.49 ms /  1268 tokens (    7.29 ms per token,   137.24 tokens per second)\n",
      "llama_print_timings:        eval time =     308.62 ms /     1 runs   (  308.62 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =    9557.58 ms /  1269 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated\n",
      "{'recon': [{'task_description': 'Perform DNS enumeration', 'status': 'done'}, {'task_description': 'Identify subdomains of 10.10.11.242', 'status': 'done'}, {'task_description': 'Reconnaissance of subdomain 10.10.11.242', 'status': 'done'}, {'status': 'inprogress', 'task_description': 'Assess credentials obtained from DNS enumeration'}], 'initial_access': [{'task_description': 'Assess credentials obtained from DNS enumeration', 'status': 'done'}, {'status': 'todo', 'task_description': 'Identify credentials for SSH (22/TCP) using OpenSSH'}], 'execution': [], 'post_exploitation': []}\n"
     ]
    }
   ],
   "source": [
    "reasoning_template = prompts[\"reasoning_module\"][\"reasoning_session_task_selection_hack_no_schema\"]\n",
    "ptt = update_ptt(reasoning_template, summary, ptt, force_add_task={\"recon\": True, \"initial_access\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c3d48-7dff-4462-877e-acb2512bc1f1",
   "metadata": {},
   "source": [
    "# Generative module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "716bf74a-129f-40c9-b922-15ae97f73fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_chat_history_str = \"\\n\".join(current_chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90f6b3ab-5236-411e-99e2-50f13b8f1ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  120221.48 ms\n",
      "llama_print_timings:      sample time =     164.44 ms /   717 runs   (    0.23 ms per token,  4360.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4444.39 ms /   636 tokens (    6.99 ms per token,   143.10 tokens per second)\n",
      "llama_print_timings:        eval time =  240055.08 ms /   716 runs   (  335.27 ms per token,     2.98 tokens per second)\n",
      "llama_print_timings:       total time =  247601.94 ms /  1352 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To assess credentials obtained from DNS enumeration against the target host, follow these steps:\n",
      "\n",
      "1. Use Nmap or similar tools to scan for open DNS ports (typically 53/TCP). If DNS is not running on default port, specify it with `-p`.\n",
      "2. Use Nmap's DNS script scan (`dns-version`, `dns-brute`, `dns-dict`, etc.) or similar scripts to enumerate DNS records for subdomains and domains related to the target host.\n",
      "3. If any subdomain(s) have been found, use tools like `dnsenum` or `sublist3r` to find more subdomains.\n",
      "4. Use `Nuclei` for automated scanning of DNS records to find potentially misconfigured or misused records that might lead to misuse or data breach.\n",
      "5. For each subdomain found, attempt to enumerate hosts by performing a ping sweep using `nmap` or similar tools (`nmap -sP --script dns-srv-query` can also be used).\n",
      "6. Attempt to identify services running on each host by using `nmap` with service detection (`nmap -sV -p- --script=banner` or `nmap --script=default`).\n",
      "7. For each service found, check if it has known vulnerabilities or misconfigurations using tools like `Nessus`, `OpenVAS`, or `Nmap` scripts (`nmap --script=vuln`).\n",
      "8. If any services are found running with default credentials (e.g., admin/admin), use tools like `Hydra` or `Medusa` for brute-force attacks against login interfaces.\n",
      "9. If any sensitive files or services are found that are accessible without authentication (e.g., running without HTTPS), use `dirb`, `dirbuster`, or `gobuster` for directory enumeration.\n",
      "10. For open ports on the host, use `Nmap` scripts (`nmap --script=vuln`) or automated vulnerability scanners like `Nessus` to assess for common vulnerabilities.\n",
      "11. If the target system is running a web application (e.g., WordPress), use plugins like `WPScan` or `Wp-sec-scan` for vulnerability scanning.\n",
      "12. If the system runs MySQL or MSSQL databases, use `mysql_nmap_script` for Nmap to automatically enumerate databases and credentials.\n",
      "13. For SSH servers, use `Hydra` or `Patator` for brute-force attacks if default passwords are found.\n",
      "14. For FTP servers, use `Hydra` or `Patator` for brute-force attacks against FTP login interfaces.\n",
      "15. If any sensitive files or services are found that are accessible without authentication, use `Wget` or `curl` with `-r` or `-R` flags to download directories recursively.\n",
      "16. If any sensitive files are found (e.g., config files), use `cat` or `more` on Unix-based systems or `type` on Windows to view the content.\n",
      "17. If there are any potential vulnerabilities identified, report them to the security team for further analysis and mitigation.\n"
     ]
    }
   ],
   "source": [
    "task = find_in_progress_task(ptt)\n",
    "generative_prompt = generative_prompt_template.format(ptt=current_chat_history_str, prompt=task)\n",
    "instructions = generator(generative_prompt)\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5651c1fb-4fa5-4f25-a892-4bc781c17624",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_chat_history_str = \"\\n\".join([user_answer, str(ptt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85438f1a-0d29-4945-9285-11cf400c5f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = find_in_progress_task(ptt)\n",
    "generative_prompt = generative_prompt_template.format(ptt=current_chat_history_str, prompt=task)\n",
    "instructions = generator(generative_prompt)\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d7217f-e66b-4bb0-b802-3cd1b9e569af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de007a-7294-4343-8828-b532a07089dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
